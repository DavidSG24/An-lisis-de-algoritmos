[
  {
    "objectID": "SegundoDavid_U5_T1.html",
    "href": "SegundoDavid_U5_T1.html",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "",
    "text": "Práctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación"
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#definimos-las-librerías-que-usaremos",
    "href": "SegundoDavid_U5_T1.html#definimos-las-librerías-que-usaremos",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Definimos las librerías que usaremos:",
    "text": "Definimos las librerías que usaremos:\n\n# Librerías estándar\nimport os\nimport json\nimport time\n\nfrom typing import Tuple, Optional\nfrom google.colab import drive\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Montamos Google Drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive"
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#carga-de-archivos-para-iniciar-procesamiento",
    "href": "SegundoDavid_U5_T1.html#carga-de-archivos-para-iniciar-procesamiento",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Carga de archivos para iniciar procesamiento",
    "text": "Carga de archivos para iniciar procesamiento\nEste bloque de código carga tres conjuntos de datos en formato JSON que contienen listas ordenadas para experimentos de intersección de conjuntos. Primero define las rutas a los archivos correspondientes a los conjuntos A (pares), B (tripletas) y C (tetrapletas), luego utiliza una función para leer cada archivo y cargar su contenido en memoria. Si algún archivo no se encuentra, muestra una advertencia. Finalmente, imprime cuántas instancias hay en cada conjunto y asigna los datos a variables individuales (dataset_a, dataset_b, dataset_c) para su uso posterior en la evaluación de algoritmos.\n\n# Definir ruta base del directorio de trabajo\ndata_dir = os.getcwd()\n\n# Definir rutas absolutas a los archivos de datos\ndataset_paths = {\n    \"A\": os.path.join(data_dir, \"/content/postinglists-for-intersection-A-k=2.json\"),\n    \"B\": os.path.join(data_dir, \"/content/postinglists-for-intersection-B-k=3.json\"),\n    \"C\": os.path.join(data_dir, \"/content/postinglists-for-intersection-C-k=4.json\")\n}\n\n# Función para cargar archivos JSON\ndef load_json_data(file_path: str):\n    try:\n        with open(file_path, 'r') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        print(f\"Archivo no encontrado -&gt; {file_path}\")\n        return None\n\n# Cargar los conjuntos de datos\ndatasets = {key: load_json_data(path) for key, path in dataset_paths.items()}\n\ndataset_a = datasets[\"A\"]\ndataset_b = datasets[\"B\"]\ndataset_c = datasets[\"C\"]\n\n\n# Reportar tamaños de los conjuntos\nprint(f\"Conjunto de datos A (pares): {len(dataset_a) if dataset_a else 0}\")\nprint(f\"Conjunto de datos B (tripletas): {len(dataset_a) if dataset_a else 0}\")\nprint(f\"Conjunto de datos C (tetrapletas): {len(dataset_a) if dataset_a else 0}\")\n\nConjunto de datos A (pares): 200\nConjunto de datos B (tripletas): 200\nConjunto de datos C (tetrapletas): 200"
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#algoritmos-de-búsqueda",
    "href": "SegundoDavid_U5_T1.html#algoritmos-de-búsqueda",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Algoritmos de búsqueda",
    "text": "Algoritmos de búsqueda\n\nFunción de búsqueda binaria\nEsta función implementa una búsqueda binaria instrumentada, que busca un elemento x dentro de una lista ordenada arr, mientras registra el número de comparaciones realizadas mediante un objeto ComparisonCounter. Devuelve el índice donde se encuentra x, o -1 si no está presente.\n\ndef instrumented_binary_search(\n    arr: list[int],\n    x: int,\n    low: int = 0,\n    high: Optional[int] = None,\n    counter: ComparisonCounter = None\n) -&gt; int:\n    \"\"\"\n    Realiza una búsqueda binaria en `arr` para encontrar `x`,\n    registrando las comparaciones realizadas mediante un contador.\n\n    Args:\n        arr (list[int]): Lista ordenada donde buscar.\n        x (int): Elemento objetivo.\n        low (int): Límite inferior del rango de búsqueda.\n        high (Optional[int]): Límite superior (inclusive).\n        counter (ComparisonCounter): Contador de comparaciones obligatorio.\n\n    Returns:\n        int: Índice de `x` si se encuentra, o -1 en caso contrario.\n    \"\"\"\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n\n    high = len(arr) - 1 if high is None else high\n\n    while low &lt;= high:\n        mid = (low + high) // 2\n        cmp = counter.compare(arr[mid], x)\n        if cmp == 0:\n            return mid\n        elif cmp &lt; 0:\n            low = mid + 1\n        else:\n            high = mid - 1\n\n    return -1\n\n\n\nDobling search (B1)\nEsta función realiza una búsqueda exponencial seguida de una búsqueda binaria para localizar un elemento x en una lista ordenada arr, comenzando desde una posición inicial start. Usa un contador (ComparisonCounter) para registrar las comparaciones realizadas. Si encuentra el elemento, retorna su índice; si no, devuelve la posición donde se debería insertar (upper bound).\n\ndef exponential_binary_search(\n    arr: list[int],\n    x: int,\n    start: int = 0,\n    counter: ComparisonCounter = None\n) -&gt; int:\n    \"\"\"\n    Realiza una búsqueda exponencial seguida de una búsqueda binaria para encontrar `x`.\n\n    Args:\n        arr (List[int]): Lista ordenada donde buscar.\n        x (int): Elemento objetivo.\n        start (int): Índice inicial desde donde buscar.\n        counter (ComparisonCounter): Objeto contador para registrar comparaciones.\n\n    Returns:\n        int: Índice de `x` si se encuentra, o posición de inserción (upper bound) si no está presente.\n    \"\"\"\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n\n    n = len(arr)\n    bound = 1\n\n    # Expansión exponencial hasta encontrar un rango que pueda contener x\n    while start + bound &lt; n and counter.compare(arr[start + bound], x) &lt; 0:\n        bound *= 2\n\n    # Definición del rango para la búsqueda binaria\n    low = start + bound // 2\n    high = min(start + bound, n - 1)\n\n    # Búsqueda binaria instrumentada dentro del rango encontrado\n    pos = instrumented_binary_search(arr, x, low, high, counter)\n\n    return pos if pos &gt;= 0 else high + 1\n\n\n\nBúsqueda B2 (doble doubling)\nEsta función implementa la búsqueda B2, que consiste en un doble salto exponencial para encontrar un rango adecuado y luego una búsqueda exponencial interna (con binaria incluida) para localizar un elemento x en una lista ordenada arr. Utiliza un ComparisonCounter para contar comparaciones y devuelve el índice de x si se encuentra, o su posición de inserción si no.\n\ndef double_exponential_search(\n    arr: list[int],\n    x: int,\n    start: int = 0,\n    counter: ComparisonCounter = None\n) -&gt; int:\n    \"\"\"\n    Búsqueda B2 (doble salto exponencial + búsqueda exponencial interna).\n\n    Args:\n        arr (list[int]): Lista ordenada donde buscar.\n        x (int): Elemento objetivo.\n        start (int): Índice inicial desde donde buscar.\n        counter (ComparisonCounter): Contador de comparaciones (requerido).\n\n    Returns:\n        int: Índice de `x` si se encuentra, o posición de inserción si no está.\n    \"\"\"\n    if counter is None:\n        raise ValueError(\"Se requiere un ComparisonCounter.\")\n\n    n = len(arr)\n    exp = 1\n\n    # Salto exponencial externo para delimitar un rango amplio\n    while start + (1 &lt;&lt; exp) &lt; n and counter.compare(arr[start + (1 &lt;&lt; exp)], x) &lt; 0:\n        exp += 1\n\n    # Definir los límites internos\n    outer_low = start + (1 &lt;&lt; (exp - 1))\n    outer_high = min(start + (1 &lt;&lt; exp), n - 1)\n\n    # Realizar búsqueda exponencial interna dentro del rango identificado\n    return exponential_binary_search(arr, x, outer_low, counter)"
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#algoritmos-de-intersección",
    "href": "SegundoDavid_U5_T1.html#algoritmos-de-intersección",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Algoritmos de intersección",
    "text": "Algoritmos de intersección\n\nMelding Intersection (ME)\nEsta función implementa el algoritmo Melding (ME) para calcular la intersección de múltiples listas ordenadas. Utiliza punteros sincronizados para comparar los elementos actuales de cada lista y avanzar solo aquellos que aún no alcanzan el valor máximo observado. Si todos coinciden, el valor se agrega a la intersección. Usa un ComparisonCounter para registrar el número de comparaciones realizadas, y retorna tanto la lista resultante como ese conteo.\n\ndef melding_intersection(\n    sets: list[list[int]],\n    counter: ComparisonCounter = None\n) -&gt; Tuple[list[int], int]:\n    \"\"\"\n    Realiza la intersección de múltiples listas ordenadas usando el algoritmo Melding (ME).\n\n    Este método compara los elementos actuales de cada lista y avanza los punteros\n    hasta que todos coincidan en un mismo valor, o se alcanza el final de alguna lista.\n\n    Args:\n        sets (list[list[int]]): Listas ordenadas a intersectar.\n        counter (ComparisonCounter, opcional): Objeto para contar comparaciones.\n\n    Returns:\n        Tuple[list[int], int]:\n            - Lista resultante con los elementos comunes.\n            - Número total de comparaciones realizadas.\n    \"\"\"\n    if counter is None:\n        counter = ComparisonCounter()\n\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n\n    result = []\n    pointers = [0] * len(sets)\n\n    while all(ptr &lt; len(sets[i]) for i, ptr in enumerate(pointers)):\n        current_values = [sets[i][ptr] for i, ptr in enumerate(pointers)]\n        max_val = max(current_values, key=lambda v: v)\n\n        # Contar comparaciones al encontrar el máximo\n        for val in current_values:\n            counter.compare(val, max_val)\n\n        if all(counter.compare(val, max_val) == 0 for val in current_values):\n            result.append(max_val)\n            pointers = [ptr + 1 for ptr in pointers]\n        else:\n            for i in range(len(sets)):\n                while pointers[i] &lt; len(sets[i]) and counter.compare(sets[i][pointers[i]], max_val) &lt; 0:\n                    pointers[i] += 1\n\n    return result, counter.count\n\n\n\nBaeza-Yates\nEsta función implementa el algoritmo Baeza-Yates utilizando búsqueda binaria instrumentada para calcular la intersección de varias listas ordenadas. Ordena las listas de menor a mayor para reducir el número de comparaciones, luego busca cada elemento del conjunto más pequeño en los demás. Usa un ComparisonCounter para registrar las comparaciones realizadas y devuelve tanto la intersección resultante como el conteo total de comparaciones.\n\ndef baeza_yates_bisection(\n    sets: list[list[int]],\n    counter: ComparisonCounter = None\n) -&gt; Tuple[list[int], int]:\n    \"\"\"\n    Aplica el algoritmo Baeza-Yates usando búsqueda binaria instrumentada para obtener la intersección\n    de múltiples listas ordenadas.\n\n    Se ordenan las listas por tamaño ascendente para minimizar comparaciones en búsquedas sucesivas.\n\n    Args:\n        sets (list[list[int]]): Listas ordenadas a intersectar.\n        counter (ComparisonCounter, opcional): Objeto para contar comparaciones.\n\n    Returns:\n        Tuple[list[int], int]:\n            - lista resultante con los elementos comunes.\n            - Número total de comparaciones realizadas.\n    \"\"\"\n    if counter is None:\n        counter = ComparisonCounter()\n\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n\n    # Ordenar listas por tamaño ascendente para eficiencia\n    sorted_sets = sorted(sets, key=len)\n    result = sorted_sets[0].copy()\n\n    for s in sorted_sets[1:]:\n        result = [e for e in result if instrumented_binary_search(s, e, 0, None, counter) != -1]\n        if not result:\n            break\n\n    return result, counter.count\n\n\n\nBaeza-Yates con búsqueda exponencial\nEsta función implementa la variante B1 del algoritmo Baeza-Yates, que utiliza búsqueda exponencial para encontrar un elemento en múltiples listas ordenadas. Para cada elemento del conjunto más pequeño, verifica si está presente en los demás conjuntos usando exponential_binary_search. Registra las comparaciones mediante un ComparisonCounter y retorna la intersección obtenida junto con el número total de comparaciones realizadas.\n\ndef baeza_yates_b1(\n    sets: list[list[int]],\n    counter: ComparisonCounter = None\n) -&gt; Tuple[list[int], int]:\n    \"\"\"\n    Aplica el algoritmo Baeza-Yates con búsqueda exponencial (B1) para intersectar múltiples listas ordenadas.\n\n    Para cada elemento del conjunto más pequeño, se verifica su presencia en los demás conjuntos\n    utilizando búsqueda exponencial seguida de búsqueda binaria.\n\n    Args:\n        sets (list[list[int]]): Listas ordenadas a intersectar.\n        counter (ComparisonCounter, opcional): Objeto para contar comparaciones.\n\n    Returns:\n        Tuple[list[int], int]:\n            - Lista con los elementos comunes.\n            - Total de comparaciones realizadas.\n    \"\"\"\n    if counter is None:\n        counter = ComparisonCounter()\n\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n\n    for e in smallest:\n        if all(exponential_binary_search(s, e, 0, counter) != -1 for s in sorted_sets[1:]):\n            result.append(e)\n\n    return result, counter.count\n\n\n\nBaeza-Yates con búsqueda exponencial (B2)\nEsta función implementa la variante B2 del algoritmo Baeza-Yates, que utiliza una búsqueda doblemente exponencial para calcular la intersección de listas ordenadas. Optimiza el proceso guardando la última posición de búsqueda en cada lista, evitando comenzar desde el inicio cada vez. Usa un ComparisonCounter para registrar comparaciones y retorna la lista de elementos comunes junto con el total de comparaciones realizadas.\n\ndef baeza_yates_b2(\n    sets: list[list[int]],\n    counter: ComparisonCounter = None\n) -&gt; Tuple[list[int], int]:\n    \"\"\"\n    Algoritmo Baeza-Yates con búsqueda doblemente exponencial\n    (B2) para intersección de listas ordenadas.\n\n    Optimiza las búsquedas recordando la última posición encontrada\n    en cada lista, evitando escanear desde el principio cada vez.\n\n    Args:\n        sets (list[list[int]]): Listas ordenadas a intersectar.\n        counter (ComparisonCounter, opcional): Objeto para contar comparaciones.\n\n    Returns:\n        Tuple[list[int], int]:\n            - Lista resultante con los elementos comunes.\n            - Número total de comparaciones realizadas.\n    \"\"\"\n    if counter is None:\n        counter = ComparisonCounter()\n\n    if not sets:\n        return [], counter.count\n    if len(sets) == 1:\n        return sets[0], counter.count\n\n    sorted_sets = sorted(sets, key=len)\n    smallest = sorted_sets[0]\n    result = []\n    positions = [0] * len(sorted_sets)\n\n    for e in smallest:\n        matched = True\n        for i in range(1, len(sorted_sets)):\n            s = sorted_sets[i]\n            start_pos = positions[i]\n            pos = double_exponential_search(s, e, start_pos, counter)\n            if pos &gt;= len(s) or counter.compare(s[pos], e) != 0:\n                matched = False\n                break\n            # actualizar la posición para la siguiente búsqueda\n            positions[i] = pos\n        if matched:\n            result.append(e)\n\n    return result, counter.count\n\n\n\n\nBarbay & Kenyon (BK)\nEsta función implementa el algoritmo Barbay & Kenyon (BK) para calcular la intersección de múltiples listas ordenadas. Utiliza una estrategia adaptativa, donde cada lista busca un candidato común utilizando una función de búsqueda eficiente (por defecto, búsqueda exponencial). Los punteros se actualizan dinámicamente para evitar retrocesos, y se registra el número total de comparaciones con un ComparisonCounter. La función devuelve la intersección resultante y el número total de comparaciones realizadas.\n\ndef bk_intersection(\n    lists: list[list[int]],\n    findpos: callable = exponential_binary_search\n) -&gt; Tuple[list[int], int]:\n    \"\"\"\n    Algoritmo de intersección Barbay & Kenyon (BK) para múltiples listas ordenadas.\n\n    Usa una estrategia adaptativa basada en búsqueda exponencial (por defecto) para encontrar coincidencias,\n    avanzando los punteros dinámicamente según el valor candidato.\n\n    Args:\n        lists (list[list[int]]): Conjuntos ordenados a intersectar.\n        findpos (callable): Función de búsqueda con conteo de comparaciones (por defecto, búsqueda exponencial + binaria).\n\n    Returns:\n        Tuple[list[int], int]:\n            - lista con los elementos comunes a todas las listas.\n            - Número total de comparaciones realizadas.\n    \"\"\"\n    counter = ComparisonCounter()\n    n = len(lists)\n    if n == 0 or any(not lst for lst in lists):\n        return [], 0\n\n    pointers = [0] * n\n    result = []\n\n    # Valor inicial candidato\n    candidate = lists[0][0]\n\n    while True:\n        match_count = 0\n\n        for i in range(n):\n            pos = findpos(lists[i], candidate, pointers[i], counter)\n            pointers[i] = pos\n\n            if pos &gt;= len(lists[i]):\n                return result, counter.count\n\n            value = lists[i][pos]\n\n            if value == candidate:\n                match_count += 1\n                if match_count == n:\n                    result.append(candidate)\n                    match_count = 0\n                pointers[i] += 1\n                if pointers[i] &gt;= len(lists[i]):\n                    return result, counter.count\n                candidate = lists[i][pointers[i]]\n            else:\n                match_count = 0\n                candidate = value\n                break\n\n    return result, counter.count  # redundante pero explícito"
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#conversión-de-resultados-a-formato-tabular",
    "href": "SegundoDavid_U5_T1.html#conversión-de-resultados-a-formato-tabular",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Conversión de Resultados a Formato Tabular",
    "text": "Conversión de Resultados a Formato Tabular\nUna vez obtenidas las métricas de evaluación, se procede a transformar los resultados en una estructura tabular para facilitar su análisis. Para ello, se construye un DataFrame plano en el que cada fila representa una combinación de algoritmo y conjunto de datos, junto con sus respectivas métricas:\n\nAlgoritmo aplicado\nTipo de conjunto (A, B o C)\nTiempo de ejecución\nNúmero de comparaciones realizadas\nLongitud de la intersección obtenida\n\nEsta representación permite comparar el comportamiento de los algoritmos de forma clara y sistemática a lo largo de distintas configuraciones experimentales.\n\ndef resultados_a_dataframe(resultados: dict) -&gt; pd.DataFrame:\n    \"\"\"\n    Convierte el diccionario de resultados en un DataFrame plano.\n\n    Args:\n        resultados (dict): Diccionario con resultados de los algoritmos.\n\n    Returns:\n        pd.DataFrame: Tabla con columnas: algoritmo, conjunto, tiempo, comparaciones, long_inter.\n    \"\"\"\n    registros = [\n        {\n            \"algoritmo\": algoritmo,\n            \"conjunto\": conjunto,\n            \"tiempo\": tiempo,\n            \"comparaciones\": comparaciones,\n            \"long_inter\": longitud\n        }\n        for algoritmo, por_conjunto in resultados.items()\n        for conjunto, ejecuciones in por_conjunto.items()\n        for tiempo, comparaciones, longitud in ejecuciones\n    ]\n    return pd.DataFrame(registros)\n\n\nresultados = evaluate_algorithms_on_datasets(dataset_a, dataset_b, dataset_c)\ndf = resultados_a_dataframe(resultados)\ndisplay(df)\n\ndf.to_csv(\"resultados_1.csv\", index=False)\n\n\n    \n\n\n\n\n\n\nalgoritmo\nconjunto\ntiempo\ncomparaciones\nlong_inter\n\n\n\n\n0\nME\nA\n0.008232\n22642\n2\n\n\n1\nME\nA\n0.004466\n4257\n6\n\n\n2\nME\nA\n0.001115\n3305\n1\n\n\n3\nME\nA\n0.001682\n5543\n16\n\n\n4\nME\nA\n0.001428\n4446\n5\n\n\n...\n...\n...\n...\n...\n...\n\n\n2995\nBK\nC\n0.000309\n521\n0\n\n\n2996\nBK\nC\n0.001811\n780\n0\n\n\n2997\nBK\nC\n0.000568\n912\n0\n\n\n2998\nBK\nC\n0.000138\n175\n0\n\n\n2999\nBK\nC\n0.000173\n284\n0\n\n\n\n\n3000 rows × 5 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nCon el objetivo de comparar de manera clara y estructurada el comportamiento de los distintos algoritmos de intersección, se generarán visualizaciones que resumen su rendimiento sobre los conjuntos de datos evaluados. En particular, se utilizarán diagramas de caja para analizar las siguientes métricas clave:\n\nTiempo de ejecución\nNúmero de comparaciones realizadas\nTamaño de la intersección obtenida\n\nEstas representaciones permitirán identificar patrones, anomalías y diferencias de eficiencia entre algoritmos bajo diversas configuraciones de entrada."
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#boxplot-de-tiempos-de-ejecución-por-algoritmo-y-conjunto",
    "href": "SegundoDavid_U5_T1.html#boxplot-de-tiempos-de-ejecución-por-algoritmo-y-conjunto",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Boxplot de Tiempos de Ejecución por Algoritmo y Conjunto",
    "text": "Boxplot de Tiempos de Ejecución por Algoritmo y Conjunto\nEste gráfico compara el rendimiento temporal de los algoritmos aplicados sobre los conjuntos A, B y C. El tiempo de ejecución, medido en segundos, permite evaluar la eficiencia computacional de cada método bajo distintas configuraciones de entrada. Esta métrica es fundamental para identificar algoritmos escalables y con buen desempeño práctico.\n\ndef plot_metric_boxplot(\n    df: pd.DataFrame,\n    metric: str,\n    title: str,\n    ylabel: str\n) -&gt; None:\n    \"\"\"\n    Genera un boxplot para una métrica dada ('tiempo', 'comparaciones', etc.).\n\n    Args:\n        df (pd.DataFrame): DataFrame con columnas 'algoritmo', 'conjunto' y la métrica.\n        metric (str): Nombre de la columna a graficar.\n        title (str): Título del gráfico.\n        ylabel (str): Etiqueta del eje Y.\n    \"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.boxplot(\n        data=df,\n        x=\"conjunto\",\n        y=metric,\n        hue=\"algoritmo\"\n    )\n    plt.title(title)\n    plt.xlabel(\"Conjunto\")\n    plt.ylabel(ylabel)\n    plt.legend(title=\"Algoritmo\")\n    plt.tight_layout()\n    plt.show()\n\n# Ejemplo de uso: gráfico de tiempos\nplot_metric_boxplot(\n    df,\n    metric=\"tiempo\",\n    title=\"Comparativa de tiempos por algoritmo y conjunto\",\n    ylabel=\"Tiempo (s)\"\n)\n\n\n\n\n\n\n\n\n\nAnálisis de Tiempos de Ejecución\nA continuación se presentan las observaciones derivadas del análisis estadístico y visualización de tiempos de ejecución para los algoritmos evaluados en los tres conjuntos de datos.\n\n\n\nConjunto A\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nMedia (s)\nDesviación estándar\nMediana (s)\nMín – Máx (s)\n\n\n\n\nBK\n0.00035\n0.00030\n0.00028\n0.00005 – 0.00337\n\n\nBY_bis\n0.00067\n0.00015\n0.00064\n0.00050 – 0.00217\n\n\nBY_B1\n0.00118\n0.00034\n0.00112\n0.00087 – 0.00481\n\n\nBY_B2\n0.00126\n0.00044\n0.00118\n0.00061 – 0.00446\n\n\nME\n0.00267\n0.00259\n0.00153\n0.00102 – 0.01116\n\n\n\nObservación: El algoritmo BK es el más rápido y consistente, mientras que ME muestra el peor rendimiento. Las variantes de Baeza-Yates tienen buen desempeño, destacando BY_bis como el mejor entre ellas.\n\n\n\nConjunto B\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nMedia (s)\nDesviación estándar\nMediana (s)\nMín – Máx (s)\n\n\n\n\nBK\n0.00066\n0.00040\n0.00055\n0.00019 – 0.00461\n\n\nBY_bis\n0.00091\n0.00019\n0.00088\n0.00060 – 0.00163\n\n\nBY_B2\n0.00134\n0.00033\n0.00125\n0.00088 – 0.00288\n\n\nBY_B1\n0.00146\n0.00037\n0.00137\n0.00100 – 0.00294\n\n\nME\n0.00446\n0.00416\n0.00287\n0.00126 – 0.01725\n\n\n\nObservación: Nuevamente, BK lidera en eficiencia, con BY_bis como opción viable. ME se vuelve más ineficiente conforme aumentan el tamaño y cantidad de listas, reflejado en su alta media y dispersión.\n\n\n\nConjunto C\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nMedia (s)\nDesviación estándar\nMediana (s)\nMín – Máx (s)\n\n\n\n\nBK\n0.00049\n0.00024\n0.00043\n0.00019 – 0.00202\n\n\nBY_B2\n0.00086\n0.00027\n0.00080\n0.00046 – 0.00176\n\n\nBY_bis\n0.00087\n0.00018\n0.00084\n0.00060 – 0.00144\n\n\nBY_B1\n0.00110\n0.00035\n0.00104\n0.00074 – 0.00269\n\n\nME\n0.00291\n0.00194\n0.00251\n0.00132 – 0.01159\n\n\n\nObservación: A pesar del aumento en la complejidad de las tuplas, BK se mantiene como el más rápido. BY_B2 mejora su rendimiento relativo gracias a su adaptabilidad. ME conserva su patrón de bajo rendimiento.\n\n\n\nObservaciones Generales\n\nBK (Barbay & Kenyon) es el algoritmo más eficiente y estable en todos los conjuntos. Su comportamiento adaptativo lo hace ideal para conjuntos ordenados de cualquier tamaño o complejidad.\nBY_bis ofrece una excelente relación entre simplicidad y rendimiento, siendo una alternativa práctica especialmente en casos donde no se requiere adaptabilidad compleja.\nLas variantes BY_B1 y BY_B2 muestran mejoras en conjuntos más grandes, aunque con mayor costo computacional.\nME (Melding) es el menos eficiente en todos los escenarios. Aunque sencillo, su estrategia de escaneo secuencial no escala bien con el número de listas ni con su longitud."
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#boxplot-del-número-de-comparaciones-por-algoritmo-y-conjunto",
    "href": "SegundoDavid_U5_T1.html#boxplot-del-número-de-comparaciones-por-algoritmo-y-conjunto",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Boxplot del Número de Comparaciones por Algoritmo y Conjunto",
    "text": "Boxplot del Número de Comparaciones por Algoritmo y Conjunto\nEsta visualización permite comparar la eficiencia computacional de los algoritmos evaluados, midiendo el número de comparaciones realizadas durante el proceso de intersección en los conjuntos A, B y C. Una menor cantidad de comparaciones sugiere un algoritmo más eficiente en términos de operaciones internas, sin comprometer necesariamente la calidad del resultado.\n\n# Gráfico boxplot del número de comparaciones por conjunto y algoritmo\nplt.figure(figsize=(10, 6))\n\nsns.boxplot(\n    data=df,\n    x=\"conjunto\",         # Conjuntos A, B, C\n    y=\"comparaciones\",    # Métrica: número de comparaciones\n    hue=\"algoritmo\"       # Color por algoritmo\n)\n\nplt.title(\"Comparativa del Número de Comparaciones por Algoritmo y Conjunto\")\nplt.xlabel(\"Conjunto de prueba\")\nplt.ylabel(\"Número de Comparaciones\")\nplt.legend(title=\"Algoritmo\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nAnálisis de Comparaciones\nEste análisis examina el número de comparaciones realizadas por cada algoritmo durante las operaciones de intersección de conjuntos ordenados. Las comparaciones son un indicador clave del costo computacional bajo el modelo de comparación.\n\n\n\nConjunto A\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nComparaciones Promedio\nMediana\nDesviación Estándar\nMín – Máx\n\n\n\n\nBK\n493\n444\n191\n59 – 1180\n\n\nBY_bis\n1361\n1353\n165\n1068 – 1865\n\n\nBY_B2\n2411\n2367\n455\n1173 – 3831\n\n\nBY_B1\n2493\n2472\n324\n1926 – 3422\n\n\nME\n9128\n4574\n10654\n3152 – 42392\n\n\n\nObservación: El algoritmo BK es claramente el más eficiente en comparaciones, con una media significativamente menor. ME destaca negativamente con una alta media y dispersión, lo que lo vuelve poco recomendable. Las variantes de BY son intermedias, siendo BY_bis la más favorable de ellas.\n\n\n\nConjunto B\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nComparaciones Promedio\nMediana\nDesviación Estándar\nMín – Máx\n\n\n\n\nBK\n1233\n1085\n405\n346 – 2376\n\n\nBY_bis\n2805\n2751\n241\n2222 – 3384\n\n\nBY_B2\n4951\n4762\n662\n3223 – 6582\n\n\nBY_B1\n5374\n5161\n780\n3833 – 7358\n\n\nME\n18321\n12888\n17246\n4417 – 85447\n\n\n\nObservación: El comportamiento observado se mantiene: BK requiere muchas menos comparaciones que cualquier otro algoritmo. A medida que aumenta la complejidad del conjunto, ME se vuelve aún menos eficiente, con un rango de comparaciones extremadamente amplio.\n\n\n\nConjunto C\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nComparaciones Promedio\nMediana\nDesviación Estándar\nMín – Máx\n\n\n\n\nBK\n1602\n1493\n375\n840 – 3017\n\n\nBY_bis\n3808\n3691\n327\n3002 – 4662\n\n\nBY_B2\n6520\n6324\n698\n4539 – 8401\n\n\nBY_B1\n7105\n6842\n870\n5114 – 9369\n\n\nME\n21521\n14518\n16510\n5406 – 56670\n\n\n\nObservación: En conjuntos más extensos (tetrapletas), el patrón se acentúa. BK sigue siendo el algoritmo más parsimonioso en comparaciones. Las estrategias más adaptativas como BY_B2 y BY_B1 incrementan su costo. ME alcanza un comportamiento fuertemente ineficiente y errático.\n\n\n\nObservaciones Generales\n\nBK (Barbay & Kenyon) domina en todos los conjuntos al requerir el menor número de comparaciones, mostrando excelente adaptabilidad y eficiencia.\nBY_bis es un buen compromiso entre simplicidad y rendimiento, siendo superior a BY_B1 y BY_B2, que son más costosos en este modelo.\nME (Melding) es el algoritmo menos eficiente, presentando altos valores medios y desviaciones grandes en todos los conjuntos. Esto lo hace poco adecuado para entornos sensibles al costo de comparación.\nEl incremento en el número de listas por conjunto (de pares a tetrapletas) incrementa naturalmente las comparaciones, pero BK logra escalar con gracia en contraste con los demás algoritmos."
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#boxplot-de-longitudes-de-intersección-como-métrica-de-control",
    "href": "SegundoDavid_U5_T1.html#boxplot-de-longitudes-de-intersección-como-métrica-de-control",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Boxplot de Longitudes de Intersección como Métrica de Control",
    "text": "Boxplot de Longitudes de Intersección como Métrica de Control\nEn esta sección se presentan diagramas de caja que muestran la distribución de las longitudes de las intersecciones generadas por cada algoritmo. Esta métrica actúa como un control de consistencia para validar que los resultados producidos por cada método sean comparables entre sí y reflejen la correcta implementación del proceso de intersección.\n\n# Gráfico boxplot de la longitud de intersección por conjunto y algoritmo\nplt.figure(figsize=(10, 6))\n\nsns.boxplot(\n    data=df,\n    x=\"conjunto\",         # Conjuntos A, B, C\n    y=\"long_inter\",       # Métrica: longitud de intersección\n    hue=\"algoritmo\"       # Agrupación por algoritmo\n)\n\nplt.title(\"Longitud de Intersección por Algoritmo y Conjunto\")\nplt.xlabel(\"Conjunto de prueba\")\nplt.ylabel(\"Tamaño de la Intersección\")\nplt.legend(title=\"Algoritmo\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nAnálisis de Longitudes de Intersección\nEste análisis examina las longitudes de intersección obtenidas por los distintos algoritmos sobre los conjuntos A, B y C. Esta métrica permite verificar que los algoritmos están produciendo resultados consistentes y comparables, actuando como mecanismo de control para validar la calidad de la intersección.\n\n\n\nConjunto A\n\n\n\nAlgoritmo\nPromedio\nMediana\nMáximo\n\n\n\n\nBY_B1\n111.6\n111\n126\n\n\nBY_bis\n20.2\n15\n59\n\n\nBY_B2\n20.1\n14\n64\n\n\nME\n19.6\n14\n61\n\n\nBK\n2.8\n1\n24\n\n\n\nObservación: El algoritmo BY_B1 muestra consistentemente las intersecciones más largas, lo que sugiere un comportamiento diferente en la lógica de intersección. Esto puede deberse a una menor precisión o mayor permisividad en su método de comparación. BK y ME presentan resultados más compactos y conservadores.\n\n\n\nConjunto B\n\n\n\nAlgoritmo\nPromedio\nMediana\nMáximo\n\n\n\n\nBY_B1\n189.7\n188\n263\n\n\nBY_bis\n25.0\n17\n93\n\n\nBY_B2\n25.1\n16\n92\n\n\nME\n23.6\n15\n86\n\n\nBK\n3.4\n2\n25\n\n\n\nObservación: Nuevamente, BY_B1 genera longitudes de intersección significativamente mayores, lo que refuerza la hipótesis de que su lógica puede ser menos estricta. BK se mantiene como el más estricto, produciendo las intersecciones más pequeñas de manera sistemática.\n\n\n\nConjunto C\n\n\n\nAlgoritmo\nPromedio\nMediana\nMáximo\n\n\n\n\nBY_B1\n112.0\n111\n128\n\n\nBY_bis\n9.2\n4\n81\n\n\nME\n7.8\n3\n70\n\n\nBY_B2\n7.7\n3\n70\n\n\nBK\n0.18\n0\n3\n\n\n\nObservación: El patrón se mantiene constante. BY_B1 genera longitudes altas incluso en conjuntos de mayor cardinalidad. BK, en contraste, produce intersecciones casi nulas en muchos casos, lo que puede estar relacionado con una política de comparación más conservadora."
  },
  {
    "objectID": "SegundoDavid_U5_T1.html#observaciones-generales-2",
    "href": "SegundoDavid_U5_T1.html#observaciones-generales-2",
    "title": "\nPráctica: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\n",
    "section": "Observaciones Generales",
    "text": "Observaciones Generales\n\nBY_B1 es el algoritmo que produce sistemáticamente las longitudes de intersección más altas en los tres conjuntos, lo que sugiere un enfoque más permisivo o amplio en su proceso de coincidencia.\nLos algoritmos BY_bis, BY_B2 y ME mantienen valores similares entre sí, con intersecciones moderadas, mostrando un balance razonable entre precisión y cobertura.\nBK genera los resultados más conservadores en todos los conjuntos, con intersecciones muy reducidas o incluso nulas, lo que podría indicar mayor precisión a costa de menor recall.\nEn general, las longitudes de intersección permiten validar la coherencia de los algoritmos: aquellos con menor número de comparaciones tienden a ser más estrictos en coincidencias, mientras que los más exhaustivos ofrecen mayor cobertura, aunque con mayor costo computacional."
  },
  {
    "objectID": "SegundoDavid_U3_T1.html",
    "href": "SegundoDavid_U3_T1.html",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "",
    "text": "Reporte Escrito: Experimentos y análisis de algoritmos de ordenamiento."
  },
  {
    "objectID": "SegundoDavid_U3_T1.html#introducción",
    "href": "SegundoDavid_U3_T1.html#introducción",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "Introducción",
    "text": "Introducción\nA lo largo de las últimas décadas se han realizado múltiples estudios para evaluar y mejorar la eficiencia de los algoritmos de ordenamiento, pues esta tarea es fundamental en la computación. Por ejemplo, investigaciones tempranas (Fosdick & Cline, 1974) realizaron exhaustivas pruebas de rendimiento de diversas variantes de quicksort, demostrando que pequeños ajustes en la implementación pueden tener un impacto significativo en el número de comparaciones y en el tiempo de ejecución. Estas pruebas sentaron las bases para posteriores estudios sobre optimización y adaptabilidad de los métodos de ordenamiento.\nPor otro lado, el desarrollo de algoritmos adaptativos ha permitido aprovechar el orden parcial existente en los datos. Estivill-Castro y Wood (1992) destacan que los algoritmos adaptativos optimizan su desempeño en función del grado de desorden de la secuencia, lo cual es especialmente relevante para listas que se encuentran casi ordenadas. En este contexto, Cook y Kim (1980) demostraron que, para listas con una alta “sortedness”, algoritmos como el Straight Insertion Sort pueden superar a métodos más generales, mientras que para listas menos ordenadas se requieren técnicas más sofisticadas como Quickersort.\nFinalmente, la introducción de estructuras de datos alternativas, como las skip lists, ha ofrecido soluciones simples y eficientes para mantener el orden de los datos sin necesidad de recurrir a estructuras complejas de equilibrio estricto. Pugh (1990) propuso que, mediante el uso de un mecanismo probabilístico para asignar niveles a los nodos, las skip lists logran un rendimiento comparable al de los árboles balanceados, pero con una implementación mucho más sencilla. Esta combinación de adaptabilidad y estructuras eficientes refleja el continuo esfuerzo por mejorar los métodos de ordenamiento en diversos contextos computacionales."
  },
  {
    "objectID": "SegundoDavid_U3_T1.html#instrucciones",
    "href": "SegundoDavid_U3_T1.html#instrucciones",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "Instrucciones:",
    "text": "Instrucciones:\n\nImplementa y compara los siguientes algoritmos de ordenamiento:\n\nHeapsort\nMergesort\nQuicksort\nBubblesort\nLa estructura de datos SkipList y utilízala para ordenar\n\nUtiliza los diferentes archivos proporcionados, los cuales tienen diferentes niveles de desorden y mide tanto el número de comparaciones como el tiempo necesario para ordenarlos.\nPor cada archivo de datos, compara todos los métodos implementados mediante figuras o tablas de datos (número de comparaciones y tiempo por separado).\nDiscute tus resultados.\n\n\n\nSolución"
  },
  {
    "objectID": "SegundoDavid_U3_T1.html#punto-1",
    "href": "SegundoDavid_U3_T1.html#punto-1",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "Punto 1",
    "text": "Punto 1\nImplementa y compara los siguientes algoritmos de ordenamiento:\n\nHeapsort\nMergesort\nQuicksort\nBubblesort\nLa estructura de datos SkipList y utilízala para ordenar\n\n\nDefinimos las librerías que usaremos:\n\nimport json\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport time\nimport random\nimport zipfile\n\n\n\nFuncíon para cargar datos en la carpeta zip\n\ndef cargar_datos_zip(ruta_zip: str) -&gt; dict:\n    \"\"\"Carga datos JSON desde un archivo ZIP.\n\n    Args:\n        ruta_zip (str): Ruta del archivo ZIP que contiene archivos JSON.\n\n    Returns:\n        dict: Diccionario donde cada llave es el nombre del archivo\n        JSON y el valor es el contenido decodificado.\n    \"\"\"\n    datos = {}\n    with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n        for nombre in archivo_zip.namelist():\n            if nombre.endswith('.json'):\n                # Eliminamos la extensión .json\n                base = os.path.splitext(nombre)[0]\n                # Quitamos el prefijo 'listas-posteo-con-'\n                base = base.replace(\"listas-posteo-con-\", \"\")\n\n                with archivo_zip.open(nombre) as archivo:\n                    datos[base] = json.load(archivo)\n    return datos\n\n\n\nImplementamos clases para el algoritmo SkipList\n\nclass Nodo:\n    \"\"\"Representa un nodo en una SkipList.\n\n    Args:\n        valor (any): Valor a almacenar en el nodo.\n        nivel (int): Nivel del nodo, que determina el número de\n        punteros que tendrá.\n\n    Attributes:\n        valor (any): Valor almacenado en el nodo.\n        siguientes (list): Lista de punteros a otros nodos en la SkipList.\n    \"\"\"\n    def __init__(self, valor, nivel: int):\n        self.valor = valor\n        self.siguientes = [None] * (nivel + 1)\n\n\nclass SkipListOrden:\n    \"\"\"Implementa una SkipList para ordenar elementos.\n\n    Args:\n        max_nivel (int, optional): Máximo nivel permitido en la SkipList.\n        Por defecto es 16.\n        probabilidad (float, optional): Probabilidad para aumentar\n        el nivel de un nodo. Por defecto es 0.5.\n\n    Attributes:\n        max_nivel (int): Valor máximo de nivel.\n        probabilidad (float): Probabilidad de incrementar el nivel.\n        nivel_actual (int): Nivel actual de la SkipList.\n        cabeza (Nodo): Nodo cabeza de la SkipList.\n        contador (int): Contador de comparaciones realizadas.\n    \"\"\"\n    def __init__(self, max_nivel: int = 16, probabilidad: float = 0.5):\n        self.max_nivel = max_nivel\n        self.probabilidad = probabilidad\n        self.nivel_actual = 0\n        self.cabeza = Nodo(-float('inf'), max_nivel)\n        self.contador = 0\n\n    def insertar(self, valor) -&gt; None:\n        \"\"\"Inserta un nuevo valor en la SkipList.\n\n        Args:\n            valor (any): Valor a insertar en la lista.\n\n        Returns:\n            None\n        \"\"\"\n        self.contador += 1\n        actual = self.cabeza\n        actualizaciones = [self.cabeza] * (self.max_nivel + 1)\n\n        for nivel in range(self.nivel_actual, -1, -1):\n            while actual.siguientes[nivel] is not None and (\n                actual.siguientes[nivel].valor &lt; valor\n            ):\n                actual = actual.siguientes[nivel]\n\n        nivel_nuevo = 0\n        while nivel_nuevo &lt; self.max_nivel and (\n            random.random() &lt; self.probabilidad\n        ):\n            nivel_nuevo += 1\n\n        nuevo = Nodo(valor, nivel_nuevo)\n\n        actual = self.cabeza\n        for nivel in range(self.nivel_actual, -1, -1):\n            while actual.siguientes[nivel] is not None and (\n                actual.siguientes[nivel].valor &lt; valor\n            ):\n                actual = actual.siguientes[nivel]\n            actualizaciones[nivel] = actual\n\n        if nivel_nuevo &gt; self.nivel_actual:\n            for i in range(self.nivel_actual + 1, nivel_nuevo + 1):\n                actualizaciones[i] = self.cabeza\n            self.nivel_actual = nivel_nuevo\n\n        for i in range(nivel_nuevo + 1):\n            nuevo.siguientes[i] = actualizaciones[i].siguientes[i]\n            actualizaciones[i].siguientes[i] = nuevo\n\n    def ordenar(self, lista: list) -&gt; tuple:\n        \"\"\"Ordena una lista utilizando la SkipList.\n\n        Args:\n            lista (list): Lista de elementos a ordenar.\n\n        Returns:\n            tuple: Una tupla que contiene el número de\n                  comparaciones realizadas.\n        \"\"\"\n        for elem in lista:\n            self.insertar(elem)\n        resultado = []\n        nodo = self.cabeza.siguientes[0]\n        while nodo:\n            resultado.append(nodo.valor)\n            nodo = nodo.siguientes[0]\n        return resultado, self.contador\n\n\n\nClase para implementar los algoritmos de ordenamieno\n\nclass AlgoritmosOrdenamiento:\n    \"\"\"Clase que contiene métodos para ordenar listas.\n\n    Métodos:\n        bubble_sort(lista: list) -&gt; tuple: Ordena la lista con Bubble Sort.\n        quick_sort(lista: list) -&gt; tuple: Ordena la lista con Quick Sort.\n        merge_sort(lista: list) -&gt; tuple: Ordena la lista con Merge Sort.\n        heap_sort(lista: list) -&gt; tuple: Ordena la lista con Heap Sort.\n    \"\"\"\n\n    # def bubble_sort(self, lista: list) -&gt; tuple:\n    #     \"\"\"Ordena una lista utilizando el algoritmo Bubble Sort.\n\n    #     Args:\n    #         lista (list): Lista de elementos a ordenar.\n\n    #     Returns:\n    #         tuple: Una tupla que contiene la lista ordenada y\n    #                el número de comparaciones realizadas.\n    #     \"\"\"\n    #     copia = lista.copy()\n    #     contador = 0\n    #     n = len(copia)\n    #     for i in range(n):\n    #         for j in range(n - i - 1):\n    #             contador += 1\n    #             if copia[j] &gt; copia[j + 1]:\n    #                 copia[j], copia[j + 1] = copia[j + 1], copia[j]\n    #     return copia, contador\n\n    def bubble_sort(self, lista: list) -&gt; tuple:\n    \"\"\"\n    Ordena una lista utilizando el algoritmo Bubble Sort adaptativo.\n\n    Args:\n        lista (list): Lista de elementos a ordenar.\n\n    Returns:\n        tuple: Una tupla que contiene la lista ordenada y el número\n               total de comparaciones realizadas.\n    \"\"\"\n    copia = lista.copy()\n    contador = 0\n    n = len(copia)\n    for i in range(n):\n        cambiado = False\n        for j in range(n - i - 1):\n            contador += 1\n            if copia[j] &gt; copia[j + 1]:\n                copia[j], copia[j + 1] = copia[j + 1], copia[j]\n                cambiado = True\n        if not cambiado:\n            break\n    return copia, contador\n\n\n    # def quick_sort(self, lista: list) -&gt; tuple:\n    #     \"\"\"Ordena una lista utilizando el algoritmo Quick Sort.\n\n    #     Args:\n    #         lista (list): Lista de elementos a ordenar.\n\n    #     Returns:\n    #         tuple: Una tupla que contiene la lista ordenada\n    #               y el número de comparaciones.\n    #     \"\"\"\n    #     copia = lista.copy()\n    #     contador = [0]\n\n    #     def particionar(arr, inicio, fin):\n    #         pivote = arr[fin]\n    #         indice = inicio - 1\n    #         comparaciones_local = 0\n    #         for k in range(inicio, fin):\n    #             comparaciones_local += 1\n    #             if arr[k] &lt;= pivote:\n    #                 indice += 1\n    #                 arr[indice], arr[k] = arr[k], arr[indice]\n    #         arr[indice + 1], arr[fin] = arr[fin], arr[indice + 1]\n    #         return indice + 1, comparaciones_local\n\n    #     def rec_quick(arr, inicio, fin):\n    #         if inicio &lt; fin:\n    #             pos, comps = particionar(arr, inicio, fin)\n    #             contador[0] += comps\n    #             rec_quick(arr, inicio, pos - 1)\n    #             rec_quick(arr, pos + 1, fin)\n\n    #     rec_quick(copia, 0, len(copia) - 1)\n    #     return copia, contador[0]\n\n\n    def quick_sort(self, lista: list) -&gt; tuple:\n    \"\"\"\n    Ordena una lista utilizando el algoritmo Quick Sort con pivote aleatorio.\n\n    Args:\n        lista (list): Lista de elementos a ordenar.\n\n    Returns:\n        tuple: Una tupla que contiene la lista ordenada y el número\n               total de comparaciones realizadas.\n    \"\"\"\n    copia = lista.copy()\n    contador = [0]\n\n    def particionar(arr, inicio, fin):\n        pivote_idx = random.randint(inicio, fin)\n        arr[pivote_idx], arr[fin] = arr[fin], arr[pivote_idx]\n        pivote = arr[fin]\n        i = inicio - 1\n        for j in range(inicio, fin):\n            contador[0] += 1\n            if arr[j] &lt;= pivote:\n                i += 1\n                arr[i], arr[j] = arr[j], arr[i]\n        arr[i + 1], arr[fin] = arr[fin], arr[i + 1]\n        return i + 1\n\n    def quicksort_rec(arr, inicio, fin):\n        if inicio &lt; fin:\n            pi = particionar(arr, inicio, fin)\n            quicksort_rec(arr, inicio, pi - 1)\n            quicksort_rec(arr, pi + 1, fin)\n\n    quicksort_rec(copia, 0, len(copia) - 1)\n    return copia, contador[0]\n\n\n    # def merge_sort(self, lista: list) -&gt; tuple:\n    #     \"\"\"Ordena una lista utilizando el algoritmo Merge Sort.\n\n    #     Args:\n    #         lista (list): Lista de elementos a ordenar.\n\n    #     Returns:\n    #         tuple: Una tupla que contiene la lista ordenada y\n    #                 el número de comparaciones realizadas.\n    #     \"\"\"\n    #     copia = lista.copy()\n    #     contador = [0]\n\n    #     def fusion(izq, der):\n    #         resultado = []\n    #         i, j = 0, 0\n    #         while i &lt; len(izq) and j &lt; len(der):\n    #             contador[0] += 1\n    #             if izq[i] &lt;= der[j]:\n    #                 resultado.append(izq[i])\n    #                 i += 1\n    #             else:\n    #                 resultado.append(der[j])\n    #                 j += 1\n    #         resultado.extend(izq[i:])\n    #         resultado.extend(der[j:])\n    #         return resultado\n\n    def merge_sort(self, lista: list) -&gt; tuple:\n        \"\"\"Ordena una lista utilizando Merge Sort in-place, minimizando copias.\n\n        Args:\n            lista (list): Lista de elementos a ordenar.\n\n        Returns:\n            tuple: Lista ordenada y número de comparaciones.\n        \"\"\"\n        copia = lista.copy()\n        contador = [0]\n        aux = [0] * len(copia)\n\n        def merge(low, mid, high):\n            i, j, k = low, mid + 1, low\n            while i &lt;= mid and j &lt;= high:\n                contador[0] += 1\n                if copia[i] &lt;= copia[j]:\n                    aux[k] = copia[i]\n                    i += 1\n                else:\n                    aux[k] = copia[j]\n                    j += 1\n                k += 1\n            while i &lt;= mid:\n                aux[k] = copia[i]\n                i += 1\n                k += 1\n            while j &lt;= high:\n                aux[k] = copia[j]\n                j += 1\n                k += 1\n            for i in range(low, high + 1):\n                copia[i] = aux[i]\n\n        def merge_sort_rec(low, high):\n            if low &lt; high:\n                mid = (low + high) // 2\n                merge_sort_rec(low, mid)\n                merge_sort_rec(mid + 1, high)\n                merge(low, mid, high)\n\n        merge_sort_rec(0, len(copia) - 1)\n        return copia, contador[0]\n\n        def rec_merge(arr):\n            if len(arr) &lt;= 1:\n                return arr\n            mitad = len(arr) // 2\n            izquierda = rec_merge(arr[:mitad])\n            derecha = rec_merge(arr[mitad:])\n            return fusion(izquierda, derecha)\n\n        ordenada = rec_merge(copia)\n        return ordenada, contador[0]\n\n    def heap_sort(self, lista: list) -&gt; tuple:\n        \"\"\"Ordena una lista utilizando el algoritmo Heap Sort.\n\n        Args:\n            lista (list): Lista de elementos a ordenar.\n\n        Returns:\n            tuple: Una tupla que contiene la lista ordenada y\n                    el número de comparaciones realizadas.\n        \"\"\"\n        copia = lista.copy()\n        contador = 0\n        n = len(copia)\n\n        def heapify(arr, tam, indice):\n            nonlocal contador\n            mayor = indice\n            izq = 2 * indice + 1\n            der = 2 * indice + 2\n            if izq &lt; tam:\n                contador += 1\n                if arr[izq] &gt; arr[mayor]:\n                    mayor = izq\n            if der &lt; tam:\n                contador += 1\n                if arr[der] &gt; arr[mayor]:\n                    mayor = der\n            if mayor != indice:\n                arr[indice], arr[mayor] = arr[mayor], arr[indice]\n                heapify(arr, tam, mayor)\n\n        for i in range(n // 2 - 1, -1, -1):\n            heapify(copia, n, i)\n        for i in range(n - 1, 0, -1):\n            copia[0], copia[i] = copia[i], copia[0]\n            heapify(copia, i, 0)\n        return copia, contador\n\n\n\nFunciones para ejecutar los algoritmos de ordenamiento y generar las gáficas.\n\ndef ejecutar_benchmark(datos: dict) -&gt; pd.DataFrame:\n    \"\"\"Ejecuta el benchmark de algoritmos de ordenamiento sobre los datos.\n\n    Args:\n        datos (dict): Diccionario con nombre de archivo y contenido.\n\n    Returns:\n        pd.DataFrame: DataFrame con las columnas de la tabla.\n    \"\"\"\n    # Se crea una instancia de AlgoritmosOrdenamiento\n    algos = AlgoritmosOrdenamiento()\n    funciones_algoritmos = {\n        'bubblesort': algos.bubble_sort,\n        'quicksort': algos.quick_sort,\n        'mergesort': algos.merge_sort,\n        'heapsort': algos.heap_sort,\n        'skiplistsort': lambda lista: SkipListOrden().ordenar(lista)\n    }\n    resultados = []\n    for nombre_archivo, contenido in datos.items():\n        lista_valores = contenido[next(iter(contenido))] if isinstance(\n            contenido, dict\n            ) else contenido\n        for nombre_algo, funcion in funciones_algoritmos.items():\n            inicio = time.time()\n            _, comps = funcion(lista_valores)\n            fin = time.time()\n            resultados.append(\n                [\n                    nombre_archivo,\n                    nombre_algo,\n                    comps,\n                    fin - inicio\n                ]\n            )\n    return pd.DataFrame(\n        resultados,\n        columns=['File', 'Algorithm', 'Comparisons', 'Time (s)']\n        )\n\ndef plot_barchart(df: pd.DataFrame, titulo: str, etiqueta_y: str) -&gt; None:\n    # Crea la figura y los ejes de forma explícita\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    # Le decimos a df.plot que use esos ejes\n    df.plot(kind='bar', ax=ax)\n\n    # Personalizamos el gráfico usando 'ax'\n    ax.set_title(titulo)\n    ax.set_xlabel(\"Archivo\")\n    ax.set_ylabel(etiqueta_y)\n    ax.tick_params(axis='x', rotation=45)\n    ax.legend(title='Algoritmo')\n\n    # Ajusta la gráfica y muestra\n    plt.tight_layout()\n    plt.show()\n\n\n## Punto 2 Utiliza los diferentes archivos proporcionados, los cuales tienen diferentes niveles de desorden y mide tanto el número de comparaciones como el tiempo necesario para ordenarlos.\n\n\nLLamadas la funciones para implementar los algoritmos a los archivos en la carpeta .zip\n\nruta_zip = \"/content/listas-posteo-con-perturbaciones.zip\"\ndatos_json = cargar_datos_zip(ruta_zip)\ndf_resultados = ejecutar_benchmark(datos_json)\ntabla_comparaciones = df_resultados.pivot(index='File', columns='Algorithm', values='Comparisons')\ntabla_tiempos = df_resultados.pivot(index='File', columns='Algorithm', values='Time (s)')\n\n\n\nTabla de Comparaciones\n\ndisplay(tabla_comparaciones)\nplot_barchart(tabla_comparaciones, \"Comparaciones por Archivo y Algoritmo\", \"Número de Comparaciones\")\n\n\n    \n\n\n\n\n\nAlgorithm\nbubblesort\nheapsort\nmergesort\nquicksort\nskiplistsort\n\n\nFile\n\n\n\n\n\n\n\n\n\nperturbaciones-p=016\n4741660\n64787\n22813\n830673\n3080\n\n\nperturbaciones-p=032\n4741660\n64715\n23799\n867552\n3080\n\n\nperturbaciones-p=064\n4741660\n64654\n25934\n185760\n3080\n\n\nperturbaciones-p=128\n4741660\n64536\n27996\n227177\n3080\n\n\nperturbaciones-p=256\n4741660\n64315\n29032\n111610\n3080\n\n\nperturbaciones-p=512\n4741660\n63936\n30263\n60118\n3080\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\n\n\n\n\n\n\nTabla de Tiempos\n\ndisplay(tabla_tiempos)\nplot_barchart(tabla_tiempos, \"Tiempo de Ejecución por Archivo y Algoritmo\", \"Tiempo (segundos)\")\n\n\n    \n\n\n\n\n\nAlgorithm\nbubblesort\nheapsort\nmergesort\nquicksort\nskiplistsort\n\n\nFile\n\n\n\n\n\n\n\n\n\nperturbaciones-p=016\n0.265685\n0.007803\n0.004450\n0.068820\n0.033273\n\n\nperturbaciones-p=032\n0.307313\n0.007571\n0.005570\n0.068720\n0.011753\n\n\nperturbaciones-p=064\n0.244071\n0.007255\n0.004545\n0.011471\n0.011337\n\n\nperturbaciones-p=128\n0.273925\n0.007136\n0.004717\n0.017832\n0.105744\n\n\nperturbaciones-p=256\n0.276331\n0.008749\n0.004862\n0.006334\n0.014385\n\n\nperturbaciones-p=512\n0.299039\n0.006739\n0.005126\n0.004216\n0.013200\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n\n\n\n\n\n\n\n## Punto 3 Por cada archivo de datos, compara todos los métodos implementados mediante figuras o tablas de datos (número de comparaciones y tiempo por separado).\n\nPara cada uno de los archivos de datos (perturbaciones-p=016, perturbaciones-p=032, perturbaciones-p=064, perturbaciones-p=128, perturbaciones-p=256 y perturbaciones-p=512), se obtuvieron dos tipos de resultados: el número de comparaciones y el tiempo de ejecución (en segundos) que cada algoritmo requirió para ordenar la lista correspondiente. En las tablas y gráficas mostradas (ver imágenes provistas), se evidencia lo siguiente:\n\nBubbleSort:\n\nGeneralmente presenta la mayor cantidad de comparaciones en todos los archivos, lo cual coincide con su complejidad teórica \\(O(n^2)\\).\n\nEn consecuencia, su tiempo de ejecución también tiende a ser elevado, sobre todo a medida que aumenta el tamaño y/o desorden de la lista.\n\nHeapSort:\n\nSu número de comparaciones se mantiene en un orden cercano a \\(O(n \\log n)\\), por lo que resulta más eficiente que BubbleSort en los archivos de mayor tamaño.\n\nEn cuanto a tiempo, logra buenos resultados, aunque en algunos casos queda por detrás de QuickSort o MergeSort.\n\nMergeSort:\n\nMantiene un comportamiento consistente de \\(O(n \\log n)\\) en la mayoría de los casos, tanto en comparaciones como en tiempo.\n\nPresenta un rendimiento estable incluso para listas muy desordenadas, pues divide el problema en sublistas y luego fusiona ordenadamente (Fosdick & Cline, 1974).\n\nQuickSort:\n\nMuestra, en general, uno de los mejores promedios de tiempo, especialmente en listas con perturbaciones medianas o grandes, confirmando su naturaleza de \\(O(n \\log n)\\) promedio (Cook & Kim, 1980).\n\nSin embargo, el número de comparaciones puede variar según la selección del pivote, aunque en estos experimentos se ve favorecido en la mayoría de los archivos.\n\nSkipListSort (uso de SkipList para ordenar):\n\nEl número de comparaciones y el tiempo tienden a ser moderados, sin llegar a ser tan alto como BubbleSort ni tan bajo como QuickSort en la mayoría de los casos.\n\nDado que la inserción en una SkipList es probabilística, puede ofrecer un desempeño cercano a \\(O(n \\log n)\\) (Pugh, 1990). Sin embargo, no siempre supera a QuickSort o MergeSort, ya que depende del patrón de inserción y de la generación aleatoria de niveles (Estivill-Castro & Wood, 1992).\n\n\nEn términos de comparaciones, BubbleSort sobresale negativamente por su alto conteo, mientras que QuickSort y MergeSort tienden a destacar por su eficiencia. Heapsort y SkipListSort se ubican en posiciones intermedias. Respecto al tiempo de ejecución, la tendencia es similar: BubbleSort es el más lento, QuickSort y MergeSort suelen ser los más rápidos, y Heapsort/SkipListSort mantienen un rendimiento aceptable en la mayoría de los casos."
  },
  {
    "objectID": "SegundoDavid_U3_T1.html#punto-4",
    "href": "SegundoDavid_U3_T1.html#punto-4",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "Punto 4",
    "text": "Punto 4\nDiscute tus resultados.\n\nLos resultados experimentales confirman las características teóricas de cada algoritmo:\n\nBubbleSort, con complejidad \\(O(n^2)\\), es poco recomendable para listas de gran tamaño o con alto desorden, ya que demanda un gran número de comparaciones y mayor tiempo de CPU.\nMergeSort y QuickSort validan su eficiencia de \\(O(n \\log n)\\). QuickSort, en particular, suele ser muy rápido para datos aleatorios o con cierto desorden, aunque en casos adversos (pivotes desfavorables) podría aumentar sus comparaciones. MergeSort, por su parte, ofrece un rendimiento constante al dividir y fusionar.\nHeapSort mantiene un comportamiento estable y eficiente en comparaciones y tiempo; sin embargo, no siempre alcanza los mejores resultados frente a QuickSort o MergeSort.\nSkipListSort se beneficia del uso probabilístico de niveles (Pugh, 1990). En la práctica, su rendimiento puede ser cercano al de los algoritmos \\(O(n \\log n)\\), pero la sobrecarga en la construcción y administración de la estructura puede hacerlo menos competitivo que QuickSort o MergeSort para algunos tamaños de lista.\n\nEn consonancia con estudios previos (Cook & Kim, 1980; Estivill-Castro & Wood, 1992), se observa que ningún algoritmo es el “mejor” en todos los escenarios. La elección depende tanto del tamaño de la lista como de su nivel de desorden. QuickSort y MergeSort suelen ser opciones sólidas para un rango amplio de situaciones. Si se sabe de antemano que las listas están casi ordenadas, algoritmos como InsertionSort o estructuras adaptativas (SkipLists) podrían tener un rendimiento aceptable, aunque en estos experimentos la comparación global muestra que QuickSort y MergeSort mantienen un balance más favorable en la mayoría de los casos."
  },
  {
    "objectID": "SegundoDavid_U3_T1.html#referencias",
    "href": "SegundoDavid_U3_T1.html#referencias",
    "title": "\nReporte Escrito: Experimentos y análisis de algoritmos de ordenamiento.\n",
    "section": "Referencias",
    "text": "Referencias\n\nCook, C. R., & Kim, D. J. (1980). Best sorting algorithm for nearly sorted lists. Communications of the ACM, 23(11), 620–628.\n\nEstivill-Castro, V., & Wood, D. (1992). A survey of adaptive sorting algorithms. ACM Computing Surveys, 24(4), 441–476.\n\nFosdick, L. D., & Cline, A. K. (Eds.). (1974). Some performance tests of “quicksort” and descendants. Smithsonian Astrophysical Observatory.\n\nPugh, W. (1990). Skip lists: A probabilistic alternative to balanced trees. Communications of the ACM, 33(6), 668–676."
  },
  {
    "objectID": "SegundoDavid_U1_T1.html",
    "href": "SegundoDavid_U1_T1.html",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "",
    "text": "Reporte Escrito: Experimentos y análisis"
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#definimos-las-funciones-que-usaremos",
    "href": "SegundoDavid_U1_T1.html#definimos-las-funciones-que-usaremos",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Definimos las funciones que usaremos:",
    "text": "Definimos las funciones que usaremos:\n\n\"\"\"\nEste notebook analiza, compara y grafica órdenes de crecimiento algorítmico,\nevaluando su impacto computacional en diferentes escenarios.\n\"\"\"\n\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\n# O(1) - Tiempo constante\ndef constante(n: int) -&gt; int:\n    \"\"\"Retorna un valor constante de 1.\n\n    Args:\n        n (int): Número de entrada (no afecta la salida).\n\n    Returns:\n        int: Siempre retorna 1.\n    \"\"\"\n    return 1\n\n# O(log n) - Crecimiento logarítmico\ndef logaritmico(n: int) -&gt; float:\n    \"\"\"Calcula el logaritmo natural de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        float: Logaritmo de n en base e.\n    \"\"\"\n    return math.log(n)\n\n# O(n) - Crecimiento lineal\ndef lineal(n: int) -&gt; int:\n    \"\"\"Retorna el mismo valor de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        int: El mismo número n.\n    \"\"\"\n    return n\n\n# O(n log n) - Crecimiento casi lineal\ndef n_log_n(n: int) -&gt; float:\n    \"\"\"Calcula n multiplicado por su logaritmo natural.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        float: Resultado de n * log(n).\n    \"\"\"\n    return n * math.log(n)\n\n# O(n^2) - Crecimiento cuadrático\ndef cuadratico(n: int) -&gt; int:\n    \"\"\"Calcula el cuadrado de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        int: n elevado al cuadrado.\n    \"\"\"\n    return n ** 2\n\n# O(n^3) - Crecimiento cúbico\ndef cubico(n: int) -&gt; int:\n    \"\"\"Calcula el cubo de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        int: n elevado al cubo.\n    \"\"\"\n    return n ** 3\n\n# O(a^n) - Crecimiento exponencial (a = 2 por defecto)\ndef exponencial(n: int, a: int = 2) -&gt; int:\n    \"\"\"Calcula a elevado a la potencia de n.\n\n    Args:\n        n (int): Número entero positivo.\n        a (int, optional): Base de la exponenciación. Por defecto es 2.\n\n    Returns:\n        int: Resultado de a^n.\n    \"\"\"\n    return a ** n\n\n# O(n!) - Crecimiento factorial\ndef factorial(n: int) -&gt; int:\n    \"\"\"Calcula el factorial de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        int: Factorial de n (n!).\n    \"\"\"\n    return math.factorial(n)\n\n# O(n^n) - Crecimiento superexponencial\ndef super_exponencial(n: int) -&gt; int:\n    \"\"\"Calcula n elevado a la potencia de n.\n\n    Args:\n        n (int): Número entero positivo.\n\n    Returns:\n        int: n^n.\n    \"\"\"\n    return n ** n"
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#observaciones",
    "href": "SegundoDavid_U1_T1.html#observaciones",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Observaciones",
    "text": "Observaciones\nLa diferencia clave entre ambas funciones radica en la forma en que escalan con el tamaño de la entrada, ya que mientras \\(O(1)\\) mantiene un tiempo de ejecución constante, \\(O(\\log n)\\) presenta un crecimiento ligero pero progresivo. En términos prácticos, para valores pequeños de \\(n\\), la diferencia entre ambas funciones es casi imperceptible; sin embargo, a medida que \\(n\\) aumenta considerablemente, \\(O(1)\\) destaca por su rapidez y eficiencia, mientras que \\(O(\\log n)\\) sigue siendo competitivo, aunque con un incremento gradual en el tiempo de ejecución. La elección entre estas funciones depende del contexto y del tamaño de la entrada, pues si la prioridad es maximizar la eficiencia temporal, \\(O(1)\\) es la mejor opción, pero si se busca un equilibrio entre escalabilidad y rendimiento en volúmenes de datos más grandes, \\(O(\\log n)\\) sigue siendo una alternativa viable y eficiente.\n2.- \\(O(n)\\) vs \\(O(n \\log n)\\)\nPara esta comparación, utilizamos un rango de valores más amplio, ya que tanto \\(O(n)\\) como \\(O(n \\log n)\\) presentan diferencias más notables a medida que \\(n\\) aumenta. Esto permite visualizar con mayor claridad cómo crecen ambas funciones y en qué punto comienza a ser significativa la diferencia en sus tiempos de ejecución.\n\n# Definimos el rango de valores\nn_values = np.arange(1, 1000)  # Rango de 1 a 999\n\n# Graficamos las funciones\nplt.plot(n_values, [lineal(n) for n in n_values], label='$O(n)$', color='red')  # O(n)\nplt.plot(n_values, [n_log_n(n) for n in n_values], label='$O(n \\log n)$', color='blue')  # O(n log n)\n\n# Configuración de la gráfica\nplt.xlabel('$n$')\nplt.ylabel('Tiempo de ejecución')\nplt.title('Comparación de $O(n)$ vs $O(n \\log n)$')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nEn esta gráfica, podemos observar cómo el tiempo de ejecución de ambas funciones aumenta a medida que crece el tamaño de la entrada \\(n\\). Sin embargo, su comportamiento difiere significativamente debido a la diferencia en sus tasas de crecimiento.\nLa función \\(O(n)\\) muestra un crecimiento estrictamente lineal, lo que significa que el tiempo de ejecución crece de manera proporcional al tamaño de la entrada. Si \\(n\\) se duplica, el tiempo de ejecución también se duplica. Esto indica que el número de operaciones realizadas es constante por cada unidad de entrada, lo que hace que esta función sea predecible y eficiente en términos de escalabilidad.\nEn contraste, la función \\(O(n \\log n)\\) tiene un crecimiento ligeramente más acelerado debido al factor logarítmico. La gráfica muestra una curva que se eleva de forma progresiva conforme aumenta \\(n\\), lo que indica que, aunque al principio la diferencia entre ambas funciones es mínima, con valores grandes de \\(n\\), la brecha en tiempo de ejecución se hace cada vez más notoria. Este tipo de complejidad es frecuente en algoritmos que requieren dividir y combinar subproblemas, como los algoritmos de ordenamiento eficientes."
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#observaciones-1",
    "href": "SegundoDavid_U1_T1.html#observaciones-1",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Observaciones",
    "text": "Observaciones\nAunque ambas funciones crecen con el tamaño de la entrada, \\(O(n \\log n)\\) lo hace a una velocidad mayor que \\(O(n)\\), por lo que, si bien en entradas pequeñas el tiempo de ejecución es similar, a medida que \\(n\\) aumenta, \\(O(n \\log n)\\) demanda más recursos computacionales. En términos prácticos, \\(O(n)\\) es preferible cuando se busca eficiencia y predictibilidad, mientras que \\(O(n \\log n)\\) es más adecuado en problemas que requieren estrategias de ordenamiento o dividir y conquistar, aunque con un costo computacional mayor.\n3.- \\(O(n^2)\\) vs \\(O(n^3)\\)\nEn este caso, optamos por un rango de valores más reducido en comparación con los anteriores, debido a que ambas funciones presentan un crecimiento significativamente más acelerado. Dado que su tasa de incremento es rápida, no es necesario utilizar valores demasiado grandes de \\(n\\) para visualizar claramente la diferencia en su comportamiento.\n\n# Definimos el rango de valores\nn_values = np.arange(1, 200)  # Rango de 1 a 199\n\n# Graficamos las funciones\nplt.plot(n_values, [cuadratico(n) for n in n_values], label='$O(n^2)$', color='red')  # O(n^2)\nplt.plot(n_values, [cubico(n) for n in n_values], label='$O(n^3)$', color='blue')  # O(n^3)\n\n# Configuración de la gráfica\nplt.xlabel('$n$')\nplt.ylabel('Tiempo de ejecución')\nplt.title('Comparación de $O(n^2)$ vs $O(n^3)$')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nEn esta gráfica, se analiza la diferencia en el tiempo de ejecución de dos funciones con complejidades algorítmicas significativamente mayores a las vistas anteriormente. Debido a la rapidez con la que crecen ambas, se ha elegido un rango más pequeño de valores de \\(n\\), lo que permite visualizar con mayor claridad la diferencia entre ellas.\nLa función \\(O(n^2)\\) se representa en la gráfica como una curva de crecimiento cuadrático, lo que significa que su tiempo de ejecución aumenta proporcionalmente al cuadrado del tamaño de la entrada. En términos prácticos, si \\(n\\) se duplica, el tiempo de ejecución se cuadruplica. Este tipo de complejidad es frecuente en algoritmos que requieren comparar pares de elementos o realizar múltiples iteraciones anidadas sobre la misma estructura de datos.\nLa función \\(O(n^3)\\) presenta un crecimiento aún más acelerado, lo que se refleja en la gráfica con una curva que se eleva más rápidamente en comparación con \\(O(n^2)\\). Su crecimiento cúbico implica que al duplicar el tamaño de la entrada, el tiempo de ejecución aumenta ocho veces, lo que representa un incremento exponencialmente mayor en comparación con el comportamiento cuadrático. Este tipo de complejidad es común en algoritmos que requieren iteraciones triples anidadas o cálculos en estructuras tridimensionales."
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#observaciones-2",
    "href": "SegundoDavid_U1_T1.html#observaciones-2",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Observaciones",
    "text": "Observaciones\nSi bien ambas funciones exhiben un crecimiento acelerado, la diferencia en sus tasas de incremento se hace evidente conforme aumenta \\(n\\), pues mientras \\(O(n^2)\\) mantiene un crecimiento controlado y moderado, la función \\(O(n^3)\\) se vuelve prohibitiva rápidamente en términos de tiempo de ejecución, lo que la hace impráctica para valores grandes de \\(n\\). Aunque en entradas pequeñas la diferencia en rendimiento puede no ser crítica, a medida que el tamaño de los datos crece, el impacto del término cúbico se vuelve dominante, incrementando significativamente el costo computacional y volviendo esencial la selección de un algoritmo más eficiente en aplicaciones donde el rendimiento sea un factor determinante.\n4.- \\(O(a^n)\\) vs \\(O(n!)\\)\nEn este caso, es necesario utilizar un rango de valores considerablemente pequeño, ya que la función factorial \\(O(n!)\\) crece a un ritmo extremadamente acelerado. Para garantizar una comparación clara y comprensible, se ha establecido un valor fijo de \\(a\\), asignándole el valor de \\(5\\) con el objetivo de evitar que el crecimiento sea trivial y proporcionar un ejemplo representativo del comportamiento de ambas funciones.\n\n# Definimos el rango de valores\nn_values = np.arange(1, 6)  # Rango de 1 a 5 debido al crecimiento acelerado de O(n!)\n\n# Graficamos las funciones\nplt.plot(n_values, [exponencial(n, 4) for n in n_values], label='$O(a^n)$', color='red')  # O(a^n) con a=4\nplt.plot(n_values, [factorial(n) for n in n_values], label='$O(n!)$', color='blue')  # O(n!)\n\n# Configuración de la gráfica\nplt.xlabel('$n$')\nplt.ylabel('Tiempo de ejecución')\nplt.title('Comparación de $O(a^n)$ vs $O(n!)$')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nPodemos observar que ambas funciones exhiben un comportamiento de crecimiento exponencial, lo que provoca un aumento drástico en el tiempo de ejecución conforme incrementa el tamaño de la entrada \\(n\\). Sin embargo, presentan diferencias notables en la velocidad con la que este crecimiento ocurre.\nLa función \\(O(a^n)\\) describe un crecimiento exponencial que se acelera a medida que \\(n\\) aumenta. La rapidez con la que se eleva la curva dependerá del valor de la constante \\(a\\), aunque en general, este tipo de complejidad es característica de algoritmos que exploran múltiples combinaciones posibles, como la búsqueda por fuerza bruta.\nLa función \\(O(n!)\\) presenta un crecimiento aún más abrupto que la exponencial, lo que se refleja en la gráfica con una curva que asciende casi verticalmente. Este comportamiento es típico de algoritmos que requieren evaluar todas las permutaciones posibles de un conjunto, lo que resulta en un aumento explosivo del tiempo de ejecución incluso para valores pequeños de \\(n\\)."
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#observaciones-3",
    "href": "SegundoDavid_U1_T1.html#observaciones-3",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Observaciones",
    "text": "Observaciones\nAunque ambas funciones experimentan un crecimiento extremadamente rápido, la función \\(O(n!)\\) incrementa su tiempo de ejecución a un ritmo considerablemente superior al de \\(O(a^n)\\), lo que la hace ineficiente incluso para valores moderados de \\(n\\). En términos prácticos, es preferible evitar algoritmos con complejidad factorial siempre que sea posible, ya que su costo computacional se vuelve prohibitivo en muy poco tiempo, mientras que \\(O(a^n)\\) podría ser aceptable en ciertos escenarios donde \\(n\\) no sea excesivamente grande; no obstante, en situaciones donde se requiera manejar entradas de gran tamaño, es recomendable buscar soluciones con una complejidad menor.\n5.- \\(O(n!)\\) vs \\(O(n^n)\\)\nAl igual que en el caso anterior, es necesario utilizar un rango de valores reducido, ya que estas funciones presentan las tasas de crecimiento más elevadas analizadas hasta el momento. En particular, \\(O(n^n)\\) exhibe un incremento aún más acelerado que \\(O(n!)\\), lo que hace que su tiempo de ejecución se dispare rápidamente conforme aumenta \\(n\\).\n\n# Definimos el rango de valores\nn_values = np.arange(1, 6)  # Rango de 1 a 5 debido al crecimiento extremadamente rápido de O(n^n)\n\n# Graficamos las funciones\nplt.plot(n_values, [factorial(n) for n in n_values], label='$O(n!)$', color='red')  # O(n!)\nplt.plot(n_values, [super_exponencial(n) for n in n_values], label='$O(n^n)$', color='blue')  # O(n^n)\n\n# Configuración de la gráfica\nplt.xlabel('$n$')\nplt.ylabel('Tiempo de ejecución')\nplt.title('Comparación de $O(n!)$ vs $O(n^n)$')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nLa gráfica ilustra la diferencia en los órdenes de crecimiento entre \\(O(n!)\\) (factorial de \\(n\\)) y \\(O(n^n)\\) (n elevado a la \\(n\\)). Aunque ambas funciones exhiben un crecimiento acelerado, la función \\(O(n^n)\\) escala a un ritmo exponencialmente mayor que \\(O(n!)\\), lo que implica una demanda computacional significativamente más elevada.\nLa función \\(O(n!)\\) presenta un crecimiento factorial, lo que significa que el tiempo de ejecución aumenta de manera extremadamente rápida conforme crece el tamaño de la entrada. Aunque sigue siendo altamente costosa, en esta comparación es la opción con menor complejidad relativa.\nLa función \\(O(n^n)\\) se distingue por una tasa de crecimiento aún más pronunciada, lo que se traduce en una curva que se eleva más rápidamente en la gráfica. Este tipo de complejidad es característica de problemas en los que se exploran combinaciones masivas, como el análisis de espacios de búsqueda en optimización y enumeración exhaustiva."
  },
  {
    "objectID": "SegundoDavid_U1_T1.html#observaciones-4",
    "href": "SegundoDavid_U1_T1.html#observaciones-4",
    "title": "\nReporte Escrito: Experimentos y análisis\n",
    "section": "Observaciones",
    "text": "Observaciones\nDado el rápido crecimiento de ambas funciones, su implementación en escenarios prácticos es inviable en la mayoría de los casos, ya que los tiempos de ejecución se vuelven excesivamente elevados incluso para valores moderados de \\(n\\). Aunque \\(O(n^n)\\) crece a una velocidad superior a \\(O(n!)\\), en la práctica, ambas funciones resultan ineficientes y poco escalables, por lo que es preferible buscar soluciones con complejidades computacionales más manejables.\nCrea una tabla donde muestre tiempos de ejecución simulados para algoritmos ficticios que tengan los órdenes de crecimiento anteriores, suponiendo que cada operación tiene un costo de 1 nanosegundo.\n\nUsa diferentes tamaños de entrada ( n = 100 ); ( n = 1000 ); ( n = 10000 ) y ( n = 100000 ).\nNota que para algunas fórmulas, los números pueden ser muy grandes (usa el foro de dudas si llegas a tener problemas).\n\n\n# Definimos los valores de entrada a evaluar\nn_values = [1, 10, 100, 1000]\n\ncomplejidades = {\n    'O(1)': constante,\n    'O(log n)': logaritmico,\n    'O(n)': lineal,\n    'O(n log n)': n_log_n,\n    'O(n^2)': cuadratico,\n    'O(n^3)': cubico,\n    'O(4^n)': lambda n: exponencial(n, 4),\n    'O(n!)': factorial,\n    'O(n^n)': super_exponencial\n}\n\n# Función para evaluar cada complejidad en los valores de n y manejar excepciones\ndef evaluar_complejidad(n_values: list, funciones: dict) -&gt; pd.DataFrame:\n    \"\"\"\n    Evalúa funciones de complejidad computacional para distintos valores de n.\n\n    Args:\n        n_values (list[int]): Lista de valores de entrada n.\n        funciones (dict[str, callable]): Diccionario con nombres de funciones y sus implementaciones.\n\n    Returns:\n        pd.DataFrame: DataFrame con los resultados de la evaluación..\n    \"\"\"\n    resultados = []\n\n    for n in n_values:\n        fila = {'n': n}\n        for nombre, funcion in funciones.items():\n            try:\n                resultado = funcion(n)\n                fila[nombre] = 'Infinito' if math.isinf(resultado) else f'{resultado:.6e}'\n            except (OverflowError, ValueError):\n                fila[nombre] = 'Error'\n        resultados.append(fila)\n\n    return pd.DataFrame(resultados)\n\n# Ejecutamos la evaluación y mostramos el DataFrame\ndf_resultado = evaluar_complejidad(n_values, complejidades)\ndisplay(df_resultado)\n\n\n    \n\n\n\n\n\n\nn\nO(1)\nO(log n)\nO(n)\nO(n log n)\nO(n^2)\nO(n^3)\nO(4^n)\nO(n!)\nO(n^n)\n\n\n\n\n0\n1\n1.000000e+00\n0.000000e+00\n1.000000e+00\n0.000000e+00\n1.000000e+00\n1.000000e+00\n4.000000e+00\n1.000000e+00\n1.000000e+00\n\n\n1\n10\n1.000000e+00\n2.302585e+00\n1.000000e+01\n2.302585e+01\n1.000000e+02\n1.000000e+03\n1.048576e+06\n3.628800e+06\n1.000000e+10\n\n\n2\n100\n1.000000e+00\n4.605170e+00\n1.000000e+02\n4.605170e+02\n1.000000e+04\n1.000000e+06\n1.606938e+60\n9.332622e+157\n1.000000e+200\n\n\n3\n1000\n1.000000e+00\n6.907755e+00\n1.000000e+03\n6.907755e+03\n1.000000e+06\n1.000000e+09\nError\nError\nError\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nEl rendimiento de un algoritmo es un factor crucial en la gestión de grandes volúmenes de datos, ya que su eficiencia determina la viabilidad de procesamiento en distintos entornos computacionales. Dependiendo de su complejidad algorítmica, algunos algoritmos escalan bien con el crecimiento de la entrada, mientras que otros pueden volverse imprácticos incluso para valores moderados de \\(n\\). A continuación, se analizan las principales complejidades y su impacto en el costo computacional:\n\n\\(O(1)\\) (Tiempo constante): El tiempo de ejecución no varía sin importar el tamaño de los datos de entrada, lo que lo convierte en el caso óptimo en términos de escalabilidad. Este tipo de comportamiento es ideal para estructuras de acceso directo, como consultas en arreglos indexados.\n\\(O(\\log n)\\) (Crecimiento logarítmico): La ejecución se incrementa muy lentamente con el tamaño de la entrada, lo que lo hace altamente eficiente en la manipulación de grandes volúmenes de datos. Es común en algoritmos de búsqueda binaria y en estructuras como árboles balanceados.\n\\(O(n)\\) (Crecimiento lineal): A medida que la cantidad de datos aumenta, el tiempo de ejecución crece de manera proporcional. Este comportamiento es adecuado para escenarios donde cada elemento debe ser procesado individualmente, pero puede generar problemas de rendimiento cuando \\(n\\) es muy grande.\n\\(O(n \\log n)\\) (Crecimiento casi lineal): Se encuentra en algoritmos de ordenamiento eficientes como Merge Sort y Quick Sort, proporcionando un balance entre velocidad y escalabilidad. Es una alternativa viable para procesar grandes volúmenes de datos sin que el costo computacional se dispare demasiado rápido.\n\\(O(n^2)\\) (Crecimiento cuadrático): La cantidad de operaciones crece exponencialmente en relación con la entrada, lo que lo hace poco eficiente para grandes conjuntos de datos. Algoritmos con esta complejidad son adecuados solo cuando se trabaja con volúmenes pequeños o cuando no se dispone de opciones más rápidas.\n\\(O(n^3)\\) (Crecimiento cúbico): Similar al cuadrático, pero con un crecimiento aún más pronunciado. Se vuelve ineficaz para grandes datos y solo se justifica en casos donde la estructura del problema requiere múltiples iteraciones anidadas.\n\\(O(4^n)\\) (Crecimiento exponencial, con \\(a=4\\)): Cada incremento en la entrada provoca una “cuatriplicación” o más en el número de operaciones, lo que lo vuelve impráctico para valores altos de \\(n\\). Se encuentra en problemas de optimización combinatoria donde se evalúan múltiples configuraciones posibles.\n\\(O(n!)\\) (Crecimiento factorial): Su ejecución escala de forma explosiva y se vuelve inmanejable incluso con valores pequeños de \\(n\\). Aparece en problemas donde se requiere evaluar todas las permutaciones posibles, como en ciertos algoritmos de fuerza bruta.\n\\(O(n^n)\\) (Crecimiento superexponencial): Representa la mayor tasa de crecimiento analizada, volviéndose inabordable incluso para entradas pequeñas. Se observa en problemas extremadamente complejos donde no se conoce una solución algorítmica eficiente.\n\nDado el alto impacto que la complejidad algorítmica tiene en el rendimiento computacional, la selección de un algoritmo adecuado es esencial cuando se manejan grandes volúmenes de información. Algoritmos de complejidad constante, logarítmica o lineal son ideales para escenarios escalables, mientras que aquellos con crecimiento cuadrático o superior deben evitarse en la medida de lo posible. En problemas donde la optimización es clave, explorar enfoques alternativos o heurísticos puede marcar la diferencia en términos de eficiencia y viabilidad."
  },
  {
    "objectID": "cambios.html",
    "href": "cambios.html",
    "title": "Cambios realizados en los reportes para la unidad de Análisis de algoritmos 2025-1",
    "section": "",
    "text": "Reporte 1: Experimentos y análisis\n\nAunque en las observaciones se sugiere eliminar las instrucciones de la actividad, se ha decidido mantenerlas debido a que proporcionan un marco de referencia útil para comprender el enfoque del trabajo desarrollado.\nLa redacción fue corregida mediante la eliminación del exceso de viñetas y la reestructuración del contenido en párrafos coherentes, lo que mejora la continuidad y claridad del texto.\nLas conclusiones fueron replanteadas con el fin de reducir la dependencia de citas textuales y fortalecer el análisis propio.\nLas referencias bibliográficas fueron ordenadas alfabéticamente conforme a los lineamientos establecidos.\nSe reestructuraron los títulos, encabezados y secciones para asegurar una presentación uniforme y acorde al formato requerido para el reporte.\n\n\n\n\nReporte 2: Experimentos y análisis de estructuras de datos.\n\nEl algoritmo merge_sort fue reescrito para optimizar su eficiencia. En lugar de utilizar múltiples copias de sublistas, se implementó una versión in-place que opera mediante el uso de índices y una lista auxiliar. Esta modificación reduce significativamente el uso de memoria y mejora el rendimiento, especialmente al trabajar con listas de gran tamaño.\nEn el caso de bubble_sort, se introdujo una mejora adaptativa que permite detener la ejecución anticipadamente cuando no se detectan intercambios durante una pasada completa. Esta optimización disminuye considerablemente el tiempo de ejecución en listas que ya se encuentran ordenadas, logrando un mejor caso con complejidad O(n).\nPara quick_sort, se modificó la lógica de selección del pivote, incorporando una estrategia aleatoria. Esta elección reduce el riesgo de caer en el peor caso con complejidad O(n²) al procesar listas parcialmente ordenadas, lo que se traduce en un rendimiento más estable y eficiente en la práctica.\n\n\n\n\nReporte 3: Experimentos y análisis de algoritmos de ordenamiento.\n\nEn este reporte no se realizaron observaciones específicas relacionadas con el contenido técnico. No obstante, se atendieron recomendaciones sobre la presentación formal del documento. Por ello, se reestructuraron los títulos, encabezados y secciones con el objetivo de asegurar una organización clara, coherente y adecuada al formato requerido.\n\n\n\nReporte 4: Experimentos y análisis de algoritmos de búsqueda por comparación.\n\nLa función search_with_skiplist fue corregida para aprovechar la estructura jerárquica de la SkipList. Se agregó el método buscar() a la clase SkipListOrden, y ahora la búsqueda se realiza con eficiencia O(log n), diferenciándose de la búsqueda secuencial. Las referencias teóricas se citaron correctamente.\nSe añadió la referencia al artículo de Bentley & Yao (1976), la cual se incorporó en el análisis de los algoritmos no acotados, fortaleciendo el respaldo académico del reporte.\nSe reestructuraron los títulos, encabezados y secciones para asegurar una presentación clara y acorde al formato establecido.\n\n\n\nReporte 5: Algoritmos de intersección y unión de conjuntos en el modelo de comparación\nEste reporte fue entregado al mismo tiempo que el presente sitio por lo cual aun no cuenta con observaciones\n\n\nNota.\nLos cambios en cuanto a código se ven reflejados sobre cada reporte al tener las funciones con observaciones comentadas para visualizar versiones anteriores."
  },
  {
    "objectID": "Algoritmos.html",
    "href": "Algoritmos.html",
    "title": "Algoritmos",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Algoritmos.html#quarto",
    "href": "Algoritmos.html#quarto",
    "title": "Algoritmos",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenido a Reportes de Algoritmos",
    "section": "",
    "text": "Explora análisis, simulaciones y visualizaciones interactivas sobre el comportamiento y eficiencia de distintos algoritmos."
  },
  {
    "objectID": "index.html#qué-encontrarás-aquí",
    "href": "index.html#qué-encontrarás-aquí",
    "title": "Bienvenido a Reportes de Algoritmos",
    "section": "🔍 ¿Qué encontrarás aquí?",
    "text": "🔍 ¿Qué encontrarás aquí?\nEste sitio contiene reportes interactivos desarrollados en Jupyter/Quarto, organizados por unidad, enfocados en:\n\nComparación de órdenes de crecimiento\nVisualización de tiempos de ejecución\nAnálisis de resultados por figura\nTablas resumen de simulación\nFundamentos teóricos bien referenciados"
  },
  {
    "objectID": "index.html#accede-a-los-reportes-por-unidad",
    "href": "index.html#accede-a-los-reportes-por-unidad",
    "title": "Bienvenido a Reportes de Algoritmos",
    "section": "📁 Accede a los reportes por unidad",
    "text": "📁 Accede a los reportes por unidad\nUsa el menú superior para explorar cada sección del proyecto."
  },
  {
    "objectID": "SegundoDavid_U2_T1.html",
    "href": "SegundoDavid_U2_T1.html",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "",
    "text": "Reporte Escrito: Experimentos y análisis de estructuras de datos.\nEl análisis de la eficiencia de algoritmos en el álgebra lineal computacional es fundamental para evaluar el rendimiento de diferentes métodos en la resolución de problemas matriciales. La multiplicación de matrices y la eliminación Gaussiana son técnicas ampliamente utilizadas en la computación científica y la inteligencia artificial, por lo que medir su desempeño es clave para seleccionar el enfoque más adecuado según el problema específico.\nLa eficiencia de estos algoritmos puede expresarse en términos de complejidad asintótica, donde la multiplicación de matrices estándar tiene una complejidad de \\(O(n^3)\\), mientras que la eliminación Gaussiana se sitúa en \\(O(n^3)\\) en su implementación tradicional. Sin embargo, las pruebas empíricas permiten observar cómo factores como la estructura de la matriz y la implementación afectan el tiempo de ejecución y el número de operaciones realizadas.\nEn este trabajo, realizamos un análisis comparativo entre la multiplicación de matrices y la eliminación Gaussiana, midiendo el número de operaciones (multiplicaciones y sumas) y el tiempo de ejecución en matrices aleatorias de diferentes tamaños. Esta evaluación permitirá identificar cuál de los métodos es más eficiente en distintos contextos computacionales y bajo qué condiciones se pueden optimizar."
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#definimos-las-funciones-que-usaremos",
    "href": "SegundoDavid_U2_T1.html#definimos-las-funciones-que-usaremos",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Definimos las funciones que usaremos:",
    "text": "Definimos las funciones que usaremos:\n\nimport numpy as np\nimport time\nimport pandas as pd\n\ndef _matrix_multiplication(\n    A: np.ndarray,\n    B: np.ndarray\n) -&gt; tuple[np.ndarray, int]:\n    \"\"\"Performs matrix multiplication using the standard algorithm.\n\n    Args:\n        A (np.ndarray): Square matrix of size (n, n).\n        B (np.ndarray): Square matrix of size (n, n).\n\n    Returns:\n        tuple[np.ndarray, int]: Resulting matrix and number of operations.\n    \"\"\"\n    n = A.shape[0]\n    C = np.zeros((n, n))\n    operations = 0  # Contador de operaciones\n    for i in range(n):\n        for j in range(n):\n            for k in range(n):\n                C[i, j] += A[i, k] * B[k, j]\n                operations += 2  # 1 multiplicación + 1 suma\n    return C, operations\n\ndef _gauss_elimination(A: np.ndarray) -&gt; tuple[np.ndarray, int]:\n    \"\"\"Applies Gaussian elimination to transform the matrix into\n      an upper triangular form.\n\n    Args:\n        A (np.ndarray): Square matrix of size (n, n).\n\n    Returns:\n        tuple[np.ndarray, int]: Triangularized matrix and number of operations.\n    \"\"\"\n    n = A.shape[0]\n    B = A.astype(float).copy()\n    operations = 0  # Contador de operaciones\n    for i in range(n):\n        # Pivoteo\n        pivot = B[i, i]\n        for j in range(i, n):\n            if pivot != 0:\n                B[i, j] /= pivot  # Normalizar la fila del pivote\n                operations += 1  # 1 división\n        for k in range(i + 1, n):\n            factor = B[k, i]\n            for j in range(i, n):\n                # Eliminar columna por debajo del pivote\n                B[k, j] -= factor * B[i, j]\n                operations += 2  # 1 multiplicación + 1 resta\n    return B, operations\n\ndef _gauss_jordan_elimination(A: np.ndarray) -&gt; tuple[np.ndarray, int]:\n    \"\"\"Applies Gauss-Jordan elimination to reduce the matrix\n      to its reduced row echelon form.\n\n    Args:\n        A (np.ndarray): Square matrix of size (n, n).\n\n    Returns:\n        tuple[np.ndarray, int]: Reduced matrix and number of operations.\n    \"\"\"\n    n = A.shape[0]\n    B = A.astype(float).copy()\n    operations = 0  # Contador de operaciones\n    for i in range(n):\n        # Pivoteo\n        pivot = B[i, i]\n        for j in range(n):\n            if pivot != 0:\n                B[i, j] /= pivot  # Normalizar la fila del pivote\n                operations += 1  # 1 división\n        for k in range(n):\n            if k != i:\n                factor = B[k, i]\n                for j in range(n):\n                    # Eliminar entradas en la columna\n                    B[k, j] -= factor * B[i, j]\n                    operations += 2  # 1 multiplicación + 1 resta\n    return B, operations\n\ndef analyze_algorithms(\n    sizes: list[int]\n) -&gt; list[tuple[int, int, float, int, float, int, float]]:\n    \"\"\"Analyzes the efficiency of matrix-related algorithms on random matrices.\n\n    Args:\n        sizes (list[int]): List of matrix sizes to evaluate.\n\n    Returns:\n        list[tuple[int, int, float, int, float, int, float]]:\n        Results of each algorithm (operation count and execution times).\n    \"\"\"\n    results = []\n    for n in sizes:\n        A = np.random.rand(n, n)\n        B = np.random.rand(n, n)\n\n        # Multiplicación de matrices\n        start_time = time.time()\n        _, mult_operations = _matrix_multiplication(A, B)\n        mult_time = time.time() - start_time\n\n        # Eliminación Gaussiana\n        start_time = time.time()\n        _, gauss_operations = _gauss_elimination(A)\n        gauss_time = time.time() - start_time\n\n        # Eliminación Gauss-Jordan\n        start_time = time.time()\n        _, gauss_jordan_operations = _gauss_jordan_elimination(A)\n        gauss_jordan_time = time.time() - start_time\n\n        results.append(\n            (\n                n,\n                mult_operations,\n                mult_time,\n                gauss_operations,\n                gauss_time,\n                gauss_jordan_operations,\n                gauss_jordan_time\n              )\n        )\n\n    return results"
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#definiciòn-de-dimensión-de-las-matrices-a-analizar-y-llamar-función-de-análisis",
    "href": "SegundoDavid_U2_T1.html#definiciòn-de-dimensión-de-las-matrices-a-analizar-y-llamar-función-de-análisis",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Definiciòn de dimensión de las matrices a analizar y llamar función de análisis",
    "text": "Definiciòn de dimensión de las matrices a analizar y llamar función de análisis\n\nsizes = [100, 300, 1000]\nresults = analyze_algorithms(sizes)"
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#mostrar-resultados",
    "href": "SegundoDavid_U2_T1.html#mostrar-resultados",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Mostrar resultados",
    "text": "Mostrar resultados\n\n\"\"\"\"\nM.O = Operaciones para multiplicación de matrices\nM.T = Tiempo para multiplicación de matrices\nG.O = Operaciones para eliminación Gaussiana\nG.T = Tiempo para eliminación Gaussiana\nGJ.O = Operaciones para eliminación Gauss-Jordan\nGJ.T = Tiempo para eliminación Gauss-Jordan\n\"\"\"\ndf = pd.DataFrame(\n      results,\n      columns=[\n          \"Tamaño\",\n          \"M.O\",\n          \"M.T\",\n          \"G.O\",\n          \"G.T\",\n          \"GJ.O\",\n          \"GJ.T\"\n          ]\n      )\ndisplay(df)\n\n\n    \n\n\n\n\n\n\nTamaño\nM.O\nM.T\nG.O\nG.T\nGJ.O\nGJ.T\n\n\n\n\n0\n100\n2000000\n0.421516\n671650\n0.113217\n1990000\n0.339208\n\n\n1\n300\n54000000\n12.071834\n18044950\n3.739929\n53910000\n9.169709\n\n\n2\n1000\n2000000000\n462.746657\n667166500\n122.178494\n1999000000\n369.795423"
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#comparación-de-complejidades-en-operaciones-matemáticas",
    "href": "SegundoDavid_U2_T1.html#comparación-de-complejidades-en-operaciones-matemáticas",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Comparación de complejidades en operaciones matemáticas",
    "text": "Comparación de complejidades en operaciones matemáticas\n\nimport matplotlib.pyplot as plt\n\nsizes = df[\"Tamaño\"]\nmult_operations = df[\"M.O\"]\ngauss_operations = df[\"G.O\"]\ngauss_jordan_operations = df[\"GJ.O\"]\n\n# Ajustar los valores del eje Y\nplt.figure(figsize=(10, 6))\nplt.plot(\n    sizes,\n    mult_operations,\n    marker='o',\n    linestyle='-',\n    color='blue',\n    label=r'Multiplicación de Matrices ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\nplt.plot(\n    sizes,\n    gauss_operations,\n    marker='s',\n    linestyle='-',\n    color='orange',\n    label=r'Eliminación Gaussiana ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\nplt.plot(\n    sizes,\n    gauss_jordan_operations,\n    marker='^',\n    linestyle='-',\n    color='green',\n    label=r'Eliminación Gauss-Jordan ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\n\n# Configurar la gráfica\nplt.xlabel(r'Tamaño de la matriz ($n$)', fontsize=12)\nplt.ylabel(r'Número de operaciones', fontsize=12)\nplt.title(\n    r'Comparación de complejidades en operaciones matemáticas',\n    fontsize=14\n)\nplt.yscale('log')  # Escala logarítmica para mejor visualización\nplt.legend()\n\n# Ajustar los límites del eje Y para incluir la curva azul\nplt.ylim(min(gauss_operations) * 0.5, max(mult_operations) * 1.5)\n\nplt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\nplt.show()"
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#comparación-de-complejidades-en-tiempo-de-ejecución",
    "href": "SegundoDavid_U2_T1.html#comparación-de-complejidades-en-tiempo-de-ejecución",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Comparación de complejidades en tiempo de ejecución",
    "text": "Comparación de complejidades en tiempo de ejecución\n\nimport matplotlib.pyplot as plt\n\n# Extraer datos del DataFrame para tiempos de ejecución\nsizes = df[\"Tamaño\"]\nmult_time = df[\"M.T\"]\ngauss_time = df[\"G.T\"]\ngauss_jordan_time = df[\"GJ.T\"]\n\n# Ajustar los valores del eje Y\nplt.figure(figsize=(10, 6))\nplt.plot(\n    sizes,\n    mult_time,\n    marker='o',\n    linestyle='-',\n    color='blue',\n    label=r'Multiplicación de Matrices ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\nplt.plot(\n    sizes,\n    gauss_time,\n    marker='s',\n    linestyle='-',\n    color='orange',\n    label=r'Eliminación Gaussiana ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\nplt.plot(\n    sizes,\n    gauss_jordan_time,\n    marker='^',\n    linestyle='-',\n    color='green',\n    label=r'Eliminación Gauss-Jordan ($O(n^3)$)',\n    markersize=8,\n    linewidth=2\n)\n\n# Configurar la gráfica\nplt.xlabel(r'Tamaño de la matriz ($n$)', fontsize=12)\nplt.ylabel(r'Tiempo de ejecución (segundos)', fontsize=12)\nplt.title(\n    r'Comparación de complejidades en tiempo de ejecución',\n    fontsize=14\n)\nplt.legend()\nplt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\nplt.show()"
  },
  {
    "objectID": "SegundoDavid_U2_T1.html#discusión-de-los-resultados-experimentales",
    "href": "SegundoDavid_U2_T1.html#discusión-de-los-resultados-experimentales",
    "title": "\nReporte Escrito: Experimentos y análisis de estructuras de datos.\n",
    "section": "Discusión de los Resultados Experimentales",
    "text": "Discusión de los Resultados Experimentales\n¿Qué puedes concluir?\n\nCrecimiento cúbico de la complejidad\nA partir de los resultados obtenidos, se confirma empíricamente que los tres algoritmos analizados (multiplicación de matrices, eliminación Gaussiana y eliminación Gauss-Jordan) presentan un crecimiento de complejidad del orden \\(O(n^3)\\). Esto es coherente con el análisis teórico, donde la multiplicación de matrices involucra \\(n^3\\) operaciones en su versión estándar, y los métodos de eliminación requieren una cantidad similar de operaciones para la transformación escalonada de la matriz y su posterior normalización (Trefethen & Bau, 1997).\nDiferencias en el número de operaciones y tiempo de ejecución\nA pesar de compartir la misma complejidad asintótica, la multiplicación de matrices requiere un mayor número de operaciones en comparación con los métodos de eliminación. Esto se debe a la estructura de los algoritmos: en la multiplicación, cada elemento de la matriz resultado requiere \\(n\\) productos escalares, mientras que en los métodos de eliminación se realizan operaciones de normalización y eliminación, reduciendo el número total de multiplicaciones y sumas necesarias (Golub & Van Loan, 2013).\n\n\n¿Cuál es el impacto de acceder los elementos contiguos en memoria de una matriz?\n\nLocalidad espacial y rendimiento en caché\nEn los algoritmos de álgebra lineal, el acceso eficiente a los datos en memoria es crucial. La localidad espacial de referencia se refiere a la tendencia de los programas a acceder a ubicaciones de memoria cercanas entre sí en cortos periodos de tiempo. Cuando una matriz se almacena en memoria en un formato contiguo (fila por fila o columna por columna), el acceso a elementos cercanos minimiza las fallas de caché, lo que mejora significativamente el rendimiento. En términos matemáticos, si consideramos una matriz \\(A\\) de tamaño \\(n \\times n\\) almacenada por filas, los accesos secuenciales a los elementos \\(A[i, j]\\) son más eficientes que acceder a \\(A[j, i]\\) debido a la organización de la memoria (Sedgewick & Wayne, 2011).\nImpacto en algoritmos de eliminación y multiplicación\nEn la multiplicación de matrices, si los accesos a la memoria no están optimizados para aprovechar la localidad de referencia, el rendimiento puede disminuir drásticamente debido a un incremento en fallos de caché. En particular, si una matriz se recorre por columnas en lugar de por filas (en un sistema con almacenamiento por filas), se pueden generar accesos no contiguos en memoria, aumentando la latencia de acceso. Esto puede hacer que un algoritmo teóricamente \\(O(n^3)\\) tenga un impacto mayor en la práctica debido a la ineficiencia en la jerarquía de memoria (Patterson & Hennessy, 2017).\n\n\n¿Qué cambiarías si utilizas matrices dispersas? ¿Cuáles serían los costos? 1. Reducción en complejidad y almacenamiento\nSi en lugar de matrices densas se utilizan matrices dispersas, el almacenamiento y la cantidad de operaciones pueden reducirse drásticamente. En una matriz dispersa con solo \\(k\\) elementos no nulos, la multiplicación de matrices puede reducirse a \\(O(k n)\\) en lugar de \\(O(n^3)\\), siempre que se utilicen estructuras eficientes como listas enlazadas o representaciones en formato CSR (Compressed Sparse Row) (Saad, 2003). Esto es particularmente útil en problemas de simulación y procesamiento de grandes volúmenes de datos, donde la mayoría de los elementos son ceros.\n\nCosto de implementación y acceso indirecto\nA pesar de la reducción en la cantidad de operaciones, los algoritmos para manejar matrices dispersas requieren acceso indirecto a los datos mediante índices adicionales. Esto puede generar una sobrecarga en comparación con el acceso secuencial en matrices densas. Además, el almacenamiento en formatos como CSR o CSC (Compressed Sparse Column) introduce una mayor latencia en la recuperación de valores individuales, lo que puede hacer que algunos cálculos sean menos eficientes en términos de tiempo de acceso a memoria (Davis, 2006)."
  },
  {
    "objectID": "SegundoDavid_U4_T1.html",
    "href": "SegundoDavid_U4_T1.html",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "",
    "text": "Reporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación."
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#definimos-las-librerías-que-usaremos",
    "href": "SegundoDavid_U4_T1.html#definimos-las-librerías-que-usaremos",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Definimos las librerías que usaremos:",
    "text": "Definimos las librerías que usaremos:\n\nimport zipfile\nimport json\nimport time\nimport random\nimport matplotlib.pyplot as plt\nfrom google.colab import drive\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\n# Montamos Google Drive\ndrive.mount('/content/drive')"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#funcíon-para-cargar-datos-de-la-carpeta-zip",
    "href": "SegundoDavid_U4_T1.html#funcíon-para-cargar-datos-de-la-carpeta-zip",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Funcíon para cargar datos de la carpeta zip",
    "text": "Funcíon para cargar datos de la carpeta zip\n\ndef leer_contenido_zip(ruta_zip: str) -&gt; dict:\n    \"\"\"Lee archivos JSON desde un archivo ZIP.\n\n    Args:\n        ruta_zip (str): Ruta al archivo ZIP.\n\n    Returns:\n        dict: Diccionario con el nombre del archivo como clave y\n              su contenido JSON como valor.\n    \"\"\"\n    contenido = {}\n    with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n        for nombre_archivo in archivo_zip.namelist():\n            with archivo_zip.open(nombre_archivo) as archivo:\n                contenido[nombre_archivo] = json.load(archivo)\n    return contenido\n\n# Definir las rutas de los archivos ZIP\nruta_consultas = '/content/drive/MyDrive/Colab Notebooks/INFOTEC/Análisis de algoritmos 2025-1/TAREA 4/Consultas-20250402.zip'\nruta_perturbaciones = '/content/drive/MyDrive/Colab Notebooks/INFOTEC/Análisis de algoritmos 2025-1/TAREA 4/listas-posteo-con-perturbaciones.zip'\n\n# Cargar los datos desde los archivos ZIP\ndatos_consultas = leer_contenido_zip(ruta_consultas)\ndatos_perturb = leer_contenido_zip(ruta_perturbaciones)\n\n# Extraer las listas de posteo de las consultas\nconsulta1 = datos_consultas['consultas-1-listas-posteo.json']\nconsulta2 = datos_consultas['consultas-2-listas-posteo.json']\nconsulta3 = datos_consultas['consultas-3-listas-posteo.json']\nconsulta4 = datos_consultas['consultas-4-listas-posteo.json']\n\n# Organizar las listas con perturbaciones en un diccionario\nlistas_perturbadas = {\n    'p016': datos_perturb['listas-posteo-con-perturbaciones-p=016.json'],\n    'p032': datos_perturb['listas-posteo-con-perturbaciones-p=032.json'],\n    'p064': datos_perturb['listas-posteo-con-perturbaciones-p=064.json'],\n    'p128': datos_perturb['listas-posteo-con-perturbaciones-p=128.json'],\n    'p256': datos_perturb['listas-posteo-con-perturbaciones-p=256.json'],\n    'p512': datos_perturb['listas-posteo-con-perturbaciones-p=512.json']\n}\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#búsqueda-binaria-acotada",
    "href": "SegundoDavid_U4_T1.html#búsqueda-binaria-acotada",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Búsqueda Binaria Acotada:",
    "text": "Búsqueda Binaria Acotada:\n\ndef bounded_binary_search(\n    lst: list,\n    key: any,\n    left: int,\n    right: int\n) -&gt; tuple:\n    \"\"\"Realiza búsqueda binaria acotada.\n\n    Args:\n        lst (list): Lista ordenada de elementos.\n        key (any): Elemento a buscar.\n        left (int): Índice inicial del rango.\n        right (int): Índice final del rango.\n\n    Returns:\n        tuple: Índice del elemento y número de comparaciones (int).\n    \"\"\"\n    num_comparisons = 0\n    while left &lt;= right:\n        mid = left + (right - left) // 2\n        num_comparisons += 1\n        if lst[mid] == key:\n            return mid, num_comparisons\n        if lst[mid] &lt; key:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1, num_comparisons"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#busqueda-secuencial-b_0",
    "href": "SegundoDavid_U4_T1.html#busqueda-secuencial-b_0",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Busqueda Secuencial \\(B_0\\):",
    "text": "Busqueda Secuencial \\(B_0\\):\n\ndef linear_search_B0(sequence: list, target_value: any) -&gt; tuple:\n    \"\"\"Realiza una búsqueda secuencial.\n\n    Args:\n        sequence (list): Lista de elementos.\n        target_value (any): Valor a buscar.\n\n    Returns:\n        tuple: Índice del valor (o -1) y número de comparaciones (int).\n    \"\"\"\n    num_comparisons = 0\n    for idx, item in enumerate(sequence):\n        num_comparisons += 1\n        if item == target_value:\n            return idx, num_comparisons\n    return -1, num_comparisons"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#búsqueda-no-acotada-b_1",
    "href": "SegundoDavid_U4_T1.html#búsqueda-no-acotada-b_1",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Búsqueda No Acotada \\(B_1\\):",
    "text": "Búsqueda No Acotada \\(B_1\\):\n\ndef unbounded_search_B1_recursive(arr: list, target: any) -&gt; tuple:\n    \"\"\"Búsqueda no acotada B1 (recursiva).\n\n    Args:\n        arr (list): Lista ordenada de elementos.\n        target (any): Valor a buscar.\n\n    Returns:\n        tuple: Índice del valor (o -1) y número de comparaciones (int).\n    \"\"\"\n    def find_bound(index, comp_count):\n        # Si se supera el tamaño del arreglo o se encuentra un valor\n        # mayor o igual al objetivo, se retorna el índice\n        if index &gt;= len(arr) or arr[index] &gt;= target:\n            return min(index, len(arr) - 1), comp_count\n        # De lo contrario, se llama recursivamente duplicando el índice\n        return find_bound(index * 2, comp_count + 1)\n\n    total_comparisons = 0\n    if not arr:\n        return -1, total_comparisons\n\n    # Comprobar si el primer elemento es el objetivo\n    total_comparisons += 1\n    if arr[0] == target:\n        return 0, total_comparisons\n\n    # Determinar recursivamente el límite superior\n    # del rango donde buscar el objetivo\n    upper_bound, rec_comps = find_bound(1, 0)\n    total_comparisons += rec_comps\n    lower_bound = upper_bound // 2\n\n    # Aplicar búsqueda binaria en el rango [lower_bound, upper_bound]\n    idx, bin_comps = bounded_binary_search(\n        arr,\n        target,\n        lower_bound,\n        upper_bound\n    )\n    total_comparisons += bin_comps\n    return idx, total_comparisons"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#búsqueda-no-acotada-b_2",
    "href": "SegundoDavid_U4_T1.html#búsqueda-no-acotada-b_2",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Búsqueda no acotada \\(B_2\\):",
    "text": "Búsqueda no acotada \\(B_2\\):\n\ndef unbounded_search_B2(arr: list, target: any) -&gt; tuple:\n    \"\"\"Búsqueda no acotada B2 (crecimiento agresivo).\n\n    Args:\n        arr (list): Lista ordenada de elementos.\n        target (any): Valor a buscar.\n\n    Returns:\n        tuple: Índice del valor (o -1) y número de comparaciones (int).\n    \"\"\"\n    if not arr:\n        return -1, 0\n\n    total_comparisons = 0\n    hi = 1\n\n    # Incrementar el límite superior de manera agresiva\n    while hi &lt; len(arr):\n        total_comparisons += 1\n        if arr[hi] &gt;= target:\n            break\n        hi = hi * 2 + 1\n\n    # Establecer el límite inferior basado en el valor actual de hi\n    low = max(0, (hi + 1) // 2)\n    hi = min(hi, len(arr) - 1)\n\n    # Realizar búsqueda binaria en el rango [low, hi]\n    index, bin_comparisons = bounded_binary_search(arr, target, low, hi)\n    total_comparisons += bin_comparisons\n\n    return index, total_comparisons"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#búsqueda-mediante-la-estructura-de-datos-skiplist",
    "href": "SegundoDavid_U4_T1.html#búsqueda-mediante-la-estructura-de-datos-skiplist",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Búsqueda mediante la estructura de datos SkipList:",
    "text": "Búsqueda mediante la estructura de datos SkipList:\n\nclass Nodo:\n    \"\"\"Representa un nodo en una SkipList.\n\n    Args:\n        valor (any): Valor a almacenar en el nodo.\n        nivel (int): Nivel del nodo, que determina el número de\n        punteros que tendrá.\n\n    Attributes:\n        valor (any): Valor almacenado en el nodo.\n        siguientes (list): Lista de punteros a otros nodos en la SkipList.\n    \"\"\"\n    def __init__(self, valor, nivel: int):\n        self.valor = valor\n        # Inicializa la lista de referencias a nodos siguientes en cada nivel\n        self.siguientes = [None] * (nivel + 1)\n\n\nclass SkipListOrden:\n    \"\"\"Implementa una SkipList para ordenar elementos.\n\n    Args:\n        max_nivel (int, optional): Máximo nivel permitido en la SkipList.\n        Por defecto es 16.\n        probabilidad (float, optional): Probabilidad para aumentar\n        el nivel de un nodo. Por defecto es 0.5.\n\n    Attributes:\n        max_nivel (int): Valor máximo de nivel.\n        probabilidad (float): Probabilidad de incrementar el nivel.\n        nivel_actual (int): Nivel actual de la SkipList.\n        cabeza (Nodo): Nodo cabeza de la SkipList.\n        contador (int): Contador de comparaciones realizadas.\n    \"\"\"\n    def __init__(self, max_nivel: int = 16, probabilidad: float = 0.5):\n        self.max_nivel = max_nivel\n        self.probabilidad = probabilidad\n        self.nivel_actual = 0  # Inicialmente la lista solo tiene el nivel 0\n        self.cabeza = Nodo(-float('inf'), max_nivel)  # Nodo cabeza con valor -infinito\n        self.contador = 0  # Contador de comparaciones realizadas\n\n    def insertar(self, valor) -&gt; None:\n        \"\"\"Inserta un nuevo valor en la SkipList.\n\n        Args:\n            valor (any): Valor a insertar en la lista.\n\n        Returns:\n            None\n        \"\"\"\n        self.contador += 1\n        actual = self.cabeza\n\n        # Guarda los nodos donde se actualizarán los punteros\n        actualizaciones = [self.cabeza] * (self.max_nivel + 1)\n\n        # Recorrer desde el nivel más alto hacia abajo para encontrar\n        # la posición correcta de inserción\n        for nivel in range(self.nivel_actual, -1, -1):\n            while actual.siguientes[nivel] is not None and (\n                actual.siguientes[nivel].valor &lt; valor\n            ):\n                actual = actual.siguientes[nivel]\n\n        # Determinar aleatoriamente el nivel del nuevo nodo\n        nivel_nuevo = 0\n        while nivel_nuevo &lt; self.max_nivel and (\n            random.random() &lt; self.probabilidad\n        ):\n            nivel_nuevo += 1\n\n        nuevo = Nodo(valor, nivel_nuevo)  # Crear el nuevo nodo\n\n        actual = self.cabeza\n        for nivel in range(self.nivel_actual, -1, -1):\n            while actual.siguientes[nivel] is not None and (\n                actual.siguientes[nivel].valor &lt; valor\n            ):\n                actual = actual.siguientes[nivel]\n            actualizaciones[nivel] = actual\n\n        # Si el nuevo nodo tiene un nivel mayor que el actual, actualizar\n        if nivel_nuevo &gt; self.nivel_actual:\n            for i in range(self.nivel_actual + 1, nivel_nuevo + 1):\n                actualizaciones[i] = self.cabeza\n            self.nivel_actual = nivel_nuevo\n\n        # Enlazar el nuevo nodo con sus correspondientes siguientes\n        for i in range(nivel_nuevo + 1):\n            nuevo.siguientes[i] = actualizaciones[i].siguientes[i]\n            actualizaciones[i].siguientes[i] = nuevo\n\n    def ordenar(self, lista: list) -&gt; tuple:\n        \"\"\"Ordena una lista utilizando la SkipList.\n\n        Args:\n            lista (list): Lista de elementos a ordenar.\n\n        Returns:\n            tuple: Una tupla que contiene el número de\n                  comparaciones realizadas.\n        \"\"\"\n        # Insertar cada elemento en la estructura SkipList\n        for elem in lista:\n            self.insertar(elem)\n\n        # Recorrer la lista desde el nivel base (0) para obtener el orden\n        resultado = []\n        nodo = self.cabeza.siguientes[0]\n        while nodo:\n            resultado.append(nodo.valor)\n            nodo = nodo.siguientes[0]\n\n        # Retorna la lista ordenada y el número de comparaciones realizadas\n        return resultado, self.contador\n\n######  Se añade este método a la clase\n    def buscar(self, valor: any) -&gt; tuple:\n        \"\"\"\n        Busca un valor en la SkipList utilizando sus niveles de acceso.\n\n        Args:\n            valor (any): Valor a buscar.\n\n        Returns:\n            tuple: True/False si se encuentra y número de comparaciones realizadas.\n        \"\"\"\n        actual = self.cabeza\n        comparaciones = 0\n        for nivel in range(self.nivel_actual, -1, -1):\n            while actual.siguientes[nivel] is not None and actual.siguientes[nivel].valor &lt; valor:\n                actual = actual.siguientes[nivel]\n                comparaciones += 1\n        actual = actual.siguientes[0]\n        comparaciones += 1\n        if actual and actual.valor == valor:\n            return True, comparaciones\n        return False, comparaciones"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#preparación-de-datos-y-estructura-auxiliar-de-búsqueda",
    "href": "SegundoDavid_U4_T1.html#preparación-de-datos-y-estructura-auxiliar-de-búsqueda",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Preparación de datos y estructura auxiliar de búsqueda",
    "text": "Preparación de datos y estructura auxiliar de búsqueda\nEste bloque de código se encarga de procesar los conjuntos de datos originales (consultas y listas con perturbaciones), organizando los términos de forma ordenada y eliminando duplicados. Además, crea instancias de la estructura SkipListOrden para cada conjunto, facilitando una estrategia de búsqueda eficiente. También se define una función auxiliar search_with_skiplist que permite realizar búsquedas secuenciales sobre la lista ordenada generada por la SkipList sin modificar la clase original.\n\ndef preparar_datos(datos: dict | list) -&gt; tuple:\n    \"\"\"Prepara términos y documentos a partir de datos.\n\n    Args:\n        datos (dict | list): Diccionario de listas de documentos o\n                             términos.\n\n    Returns:\n        tuple: Lista de términos ordenados y\n                diccionario {término: [documentos]}.\n    \"\"\"\n    if isinstance(datos, dict):\n        terminos = sorted(list(datos.keys()))\n        diccionario_docs = {}\n        for termino in terminos:\n            # Convertir la lista de documentos a un conjunto\n            # para eliminar duplicados, luego ordenarlos.\n            documentos = sorted(list(set(datos[termino])))\n            diccionario_docs[termino] = documentos\n    elif isinstance(datos, list):\n        terminos = sorted(datos)\n        diccionario_docs = {}\n        for termino in terminos:\n            diccionario_docs[termino] = []\n    else:\n        raise ValueError(\"Formato de datos no reconocido\")\n\n    return terminos, diccionario_docs\n\n# Procesar cada conjunto de datos\nconjuntos = {\n    'consultas_1': preparar_datos(consulta1),\n    'consultas_2': preparar_datos(consulta2),\n    'consultas_3': preparar_datos(consulta3),\n    'consultas_4': preparar_datos(consulta4),\n    'perturbaciones_p016': preparar_datos(listas_perturbadas['p016']),\n    'perturbaciones_p032': preparar_datos(listas_perturbadas['p032']),\n    'perturbaciones_p064': preparar_datos(listas_perturbadas['p064']),\n    'perturbaciones_p128': preparar_datos(listas_perturbadas['p128']),\n    'perturbaciones_p256': preparar_datos(listas_perturbadas['p256']),\n    'perturbaciones_p512': preparar_datos(listas_perturbadas['p512'])\n}\n\n# Crear SkipLists utilizando la clase SkipListOrden para cada conjunto\nskip_lists_orden = {}\nfor nombre, (terminos, _) in conjuntos.items():\n    lista_orden = SkipListOrden()  # Instanciar de la clase SkipListOrden\n    for termino in terminos:\n        lista_orden.insertar(termino)\n    skip_lists_orden[nombre] = lista_orden\n\n# def search_with_skiplist(skip_list: SkipListOrden, target: any) -&gt; tuple:\n#     \"\"\"Busca un valor usando la lista ordenada de una SkipList.\n\n#     Args:\n#         skip_list (SkipListOrden): Instancia de SkipList ya construida.\n#         target (any): Valor a buscar.\n\n#     Returns:\n#         tuple: Índice del valor (o -1) y número de comparaciones (int).\n#     \"\"\"\n#     # Llama solo para obtener la lista ordenada\n#     sorted_terms, _ = skip_list.ordenar([])\n#     comparisons = 0\n#     for i, val in enumerate(sorted_terms):\n#         comparisons += 1\n#         if val == target:\n#             return i, comparisons\n#     return -1, comparisons\n\n\ndef search_with_skiplist(skip_list: SkipListOrden, target: any) -&gt; tuple:\n    \"\"\"\n    Realiza búsqueda en SkipList usando su estructura interna (no secuencial).\n\n    Args:\n        skip_list (SkipListOrden): Instancia ya construida.\n        target (any): Valor a buscar.\n\n    Returns:\n        tuple: Índice simulado (-1 si no se encuentra) y comparaciones.\n    \"\"\"\n    encontrado, comparaciones = skip_list.buscar(target)\n    return (0 if encontrado else -1), comparaciones"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#funciones-para-comparar-los-métodos-implementados-por-archivo-de-consulta",
    "href": "SegundoDavid_U4_T1.html#funciones-para-comparar-los-métodos-implementados-por-archivo-de-consulta",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Funciones para comparar los métodos implementados por archivo de consulta",
    "text": "Funciones para comparar los métodos implementados por archivo de consulta\n\ndef evaluate_dataset_alternative(\n    dataset_key: str,\n    custom_queries: list = None\n) -&gt; dict:\n    \"\"\"Evalúa un conjunto de datos por clave.\n\n    Args:\n        dataset_key (str): Clave del conjunto\n                           ('consultas_1', 'perturbaciones_p016', etc.).\n        custom_queries (list, optional): Términos a buscar\n                                         (por defecto se usan todos).\n\n    Returns:\n        dict: Promedios de tiempo y comparaciones por algoritmo.\n    \"\"\"\n    data_terms, data_docs = conjuntos[dataset_key]\n    skip_instance = skip_lists_orden[dataset_key]\n    query_list = (\n        custom_queries if custom_queries is not None else data_terms\n    )\n    evaluation_results = evaluate_search_algorithms(\n        data_terms,\n        data_docs,\n        skip_instance,\n        query_list\n    )\n    return evaluation_results\n\n# Evaluación de los conjuntos de consultas\nresults1 = evaluate_dataset_alternative('consultas_1')\nresults2 = evaluate_dataset_alternative('consultas_2')\nresults3 = evaluate_dataset_alternative('consultas_3')\nresults4 = evaluate_dataset_alternative('consultas_4')\n\n# Evaluación de los conjuntos de perturbaciones\nresults_p016 = evaluate_dataset_alternative('perturbaciones_p016')\nresults_p032 = evaluate_dataset_alternative('perturbaciones_p032')\nresults_p064 = evaluate_dataset_alternative('perturbaciones_p064')\nresults_p128 = evaluate_dataset_alternative('perturbaciones_p128')\nresults_p256 = evaluate_dataset_alternative('perturbaciones_p256')\nresults_p512 = evaluate_dataset_alternative('perturbaciones_p512')"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#tablas-de-calor-heatmaps-de-resultados",
    "href": "SegundoDavid_U4_T1.html#tablas-de-calor-heatmaps-de-resultados",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Tablas de calor (heatmaps) de resultados",
    "text": "Tablas de calor (heatmaps) de resultados\nEsta función genera visualizaciones tipo heatmap para mostrar los tiempos de ejecución y comparaciones promedio por algoritmo. Permite comparar fácilmente el rendimiento de búsqueda en diferentes conjuntos de consultas y niveles de perturbación.\n\ndef plot_results_tables_modern(\n    consultas_results: list,\n    perturbaciones_results: list\n) -&gt; None:\n    \"\"\"Genera tablas visuales (heatmaps) para consultas y perturbaciones.\n\n    Args:\n        consultas_results (list): Resultados promedio de consultas.\n        perturbaciones_results (list): Promedio de perturbaciones.\n    \"\"\"\n    algorithms = [\n        'binary',\n        'sequential',\n        'unbounded_B1',\n        'unbounded_B2',\n        'skip_list'\n    ]\n    labels = [\n        'Binaria',\n        'Secuencial',\n        'No Acotada B1',\n        'No Acotada B2',\n        'SkipList'\n    ]\n    consultas_names = [\n        f\"Consultas {i+1}\" for i in range(len(consultas_results))\n    ]\n    perturb_names = ['p016', 'p032', 'p064', 'p128', 'p256', 'p512']\n\n    def build_dataframe(\n        results: list,\n        names: list,\n        value_key: str\n    ) -&gt; pd.DataFrame:\n        \"\"\"Crea un DataFrame para tiempos o comparaciones.\n\n        Args:\n            results (list): Resultados por conjunto.\n            names (list): Nombres de columnas.\n            value_key (str): 'time' o 'comparisons'.\n\n        Returns:\n            pd.DataFrame: DataFrame listo para graficar.\n        \"\"\"\n        data = []\n        for alg in algorithms:\n            row = [res[alg][value_key] for res in results]\n            data.append(row)\n        df = pd.DataFrame(data, index=labels, columns=names)\n        return df\n\n    def plot_table(\n        df: pd.DataFrame,\n        title: str,\n        cmap: str = 'Blues'\n    ) -&gt; None:\n        \"\"\"Grafica un DataFrame como heatmap.\n\n        Args:\n            df (pd.DataFrame): DataFrame con resultados.\n            title (str): Título del gráfico.\n            cmap (str, optional): Mapa de color. Default 'Blues'.\n        \"\"\"\n        plt.figure(figsize=(10, 6))\n        sns.heatmap(\n            df,\n            annot=True,\n            fmt=\".4g\",\n            cmap=cmap,\n            cbar=True,\n            linewidths=.5,\n            linecolor='gray'\n        )\n        plt.title(title, fontsize=14, fontweight='bold')\n        plt.yticks(rotation=0)\n        plt.xticks(rotation=30)\n        plt.tight_layout()\n        plt.show()\n\n    # Construir y graficar tablas para consultas\n    df_time_consultas = build_dataframe(\n        consultas_results,\n        consultas_names,\n        'time'\n    )\n    df_comp_consultas = build_dataframe(\n        consultas_results,\n        consultas_names,\n        'comparisons'\n    )\n    plot_table(\n        df_time_consultas,\n        \"Tiempo de Ejecución - Consultas\",\n        cmap='PuBu'\n    )\n    plot_table(\n        df_comp_consultas,\n        \"Comparaciones - Consultas\",\n        cmap='Oranges'\n    )\n\n    # Construir y graficar tablas para perturbaciones\n    df_time_perturbs = build_dataframe(\n        perturbaciones_results,\n        perturb_names,\n        'time'\n    )\n    df_comp_perturbs = build_dataframe(\n        perturbaciones_results,\n        perturb_names,\n        'comparisons'\n    )\n    plot_table(\n        df_time_perturbs,\n        \"Tiempo de Ejecución - Perturbaciones\",\n        cmap='GnBu'\n    )\n    plot_table(\n        df_comp_perturbs,\n        \"Comparaciones - Perturbaciones\",\n        cmap='YlOrBr'\n    )"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#gráficos-de-barras-comparativos",
    "href": "SegundoDavid_U4_T1.html#gráficos-de-barras-comparativos",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Gráficos de barras comparativos",
    "text": "Gráficos de barras comparativos\nEsta función visualiza el rendimiento de los algoritmos de búsqueda mediante gráficos de barras. Compara tiempo de ejecución y número de comparaciones en conjuntos de consultas y perturbaciones, permitiendo observar fácilmente las diferencias entre binaria, secuencial, no acotadas y SkipList.\n\ndef plot_bar_results_modern(\n    consultas_results: list,\n    perturbaciones_results: list\n) -&gt; None:\n    \"\"\"Genera gráficos de barras para consultas y perturbaciones.\n\n    Args:\n        consultas_results (list): Resultados promedio por algoritmo\n                                  en conjuntos de consulta.\n        perturbaciones_results (list): Resultados promedio por\n                            algoritmo en conjuntos con perturbaciones.\n    \"\"\"\n    algorithms = [\n        'binary',\n        'sequential',\n        'unbounded_B1',\n        'unbounded_B2',\n        'skip_list'\n    ]\n    labels = [\n        'Binaria',\n        'Secuencial',\n        'No Acotada B1',\n        'No Acotada B2',\n        'SkipList'\n    ]\n    perturb_names = ['p016', 'p032', 'p064', 'p128', 'p256', 'p512']\n\n    # Configuración estética\n    colors = ['#4C72B0', '#55A868', '#C44E52', '#8172B3', '#CCB974']\n    bar_width = 0.15\n\n    def plot_grouped_bars(\n        ax: plt.Axes,\n        data: list,\n        group_labels: list,\n        title: str,\n        ylabel: str\n    ) -&gt; None:\n        \"\"\"Dibuja un grupo de barras comparativas.\n\n        Args:\n            ax (plt.Axes): Eje de matplotlib para graficar.\n            data (list): Lista de listas con valores por algoritmo.\n            group_labels (list): Etiquetas de cada grupo.\n            title (str): Título del gráfico.\n            ylabel (str): Etiqueta del eje Y.\n        \"\"\"\n        x = np.arange(len(algorithms))\n        for i, group in enumerate(data):\n            ax.bar(\n                x + i * bar_width,\n                group, width=bar_width,\n                label=group_labels[i],\n                color=colors[i % len(colors)],\n                edgecolor='black'\n            )\n\n        ax.set_xticks(x + (len(data) - 1) * bar_width / 2)\n        ax.set_xticklabels(labels, rotation=30)\n        ax.set_title(title, fontsize=14, fontweight='bold')\n        ax.set_ylabel(ylabel)\n        ax.legend()\n        ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.6)\n\n    # Preparar datos\n    consultas_times = [\n        [\n            res[alg]['time'] for alg in algorithms\n        ] for res in consultas_results\n    ]\n    consultas_comps = [\n        [\n            res[alg]['comparisons'] for alg in algorithms\n        ] for res in consultas_results\n    ]\n    perturb_times = [\n        [\n            res[alg]['time'] for alg in algorithms\n        ] for res in perturbaciones_results\n    ]\n    perturb_comps = [\n        [\n            res[alg]['comparisons'] for alg in algorithms\n        ] for res in perturbaciones_results\n    ]\n\n    # Crear subplots\n    fig, axs = plt.subplots(2, 2, figsize=(20, 12))\n    fig.suptitle(\n        'Comparación de Algoritmos de Búsqueda',\n        fontsize=18, fontweight='bold'\n    )\n\n    # Gráficas\n    plot_grouped_bars(\n        axs[0, 0],\n        consultas_times,\n        [f'Consultas {i+1}' for i in range(len(consultas_results))],\n        'Tiempo de Ejecución - Consultas', 'Tiempo (segundos)'\n    )\n    plot_grouped_bars(\n        axs[0, 1],\n        consultas_comps,\n        [f'Consultas {i+1}' for i in range(len(consultas_results))],\n        'Comparaciones - Consultas', 'Comparaciones')\n    plot_grouped_bars(\n        axs[1, 0],\n        perturb_times,\n        [f'p={p}' for p in perturb_names],\n        'Tiempo de Ejecución - Perturbaciones', 'Tiempo (segundos)')\n    plot_grouped_bars(\n        axs[1, 1],\n        perturb_comps,\n        [f'p={p}' for p in perturb_names],\n        'Comparaciones - Perturbaciones', 'Comparaciones')\n\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.show()"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#tablas-de-calor-heatmaps-de-resultados-1",
    "href": "SegundoDavid_U4_T1.html#tablas-de-calor-heatmaps-de-resultados-1",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Tablas de calor (heatmaps) de resultados",
    "text": "Tablas de calor (heatmaps) de resultados\n\nconsultas_results = [results1, results2, results3, results4]\nperturbaciones_results = [\n    results_p016,\n    results_p032,\n    results_p064,\n    results_p128,\n    results_p256,\n    results_p512\n]\n\nplot_results_tables_modern(consultas_results, perturbaciones_results)"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#gráficos-de-barras-entre-algoritmos-de-búsqueda.",
    "href": "SegundoDavid_U4_T1.html#gráficos-de-barras-entre-algoritmos-de-búsqueda.",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Gráficos de barras entre algoritmos de búsqueda.",
    "text": "Gráficos de barras entre algoritmos de búsqueda.\n\n# Generación de gráficos entre algoritmos de búsqueda\nconsultas_results = [results1, results2, results3, results4]\nperturbaciones_results = [\n    results_p016,\n    results_p032,\n    results_p064,\n    results_p128,\n    results_p256,\n    results_p512\n]\n\nplot_bar_results_modern(consultas_results, perturbaciones_results)"
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#análisis-para-consultas",
    "href": "SegundoDavid_U4_T1.html#análisis-para-consultas",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Análisis para consultas",
    "text": "Análisis para consultas\n\nLa búsqueda binaria demostró ser altamente eficiente, con tiempos muy bajos (entre 2.5e-6 y 4.3e-6 segundos) y un número de comparaciones que se mantuvo relativamente bajo (de 3.4 a 12.1 en promedio). Esto confirma su desempeño óptimo en arreglos ordenados y valida su complejidad de O(log n). La eficiencia se mantuvo estable en todos los archivos de consulta, lo cual respalda su uso como método preferido cuando el tamaño del conjunto es conocido y los datos están ordenados (Cormen et al., 2022).\nLa búsqueda secuencial (B₀) mostró el rendimiento más bajo entre todos los métodos evaluados. Sus tiempos fueron significativamente más altos (alrededor de 0.00037 a 0.00041 segundos) y el número de comparaciones fue extremadamente alto (4688 a 5000), en concordancia con su complejidad O(n). Este resultado es consistente con la literatura (Bentley & McGeoch, 1985), que posiciona esta estrategia como subóptima en conjuntos grandes o cuando se requiere eficiencia.\nLas búsquedas no acotadas B₁ y B₂ ofrecieron una alternativa válida a la búsqueda binaria, especialmente útil en contextos donde el tamaño del arreglo no es conocido. Aunque su tiempo fue ligeramente mayor, las comparaciones promediaron entre 13.6 y 23.4, lo que las vuelve aceptables en escenarios dinámicos. B₂ presentó un mejor desempeño que B₁ en todos los casos, evidenciando una mayor eficiencia en la delimitación del rango de búsqueda (Bentley y Yao, 1976).\nSkipList, por su parte, tuvo el peor desempeño en tiempo de ejecución (0.0010 a 0.0015 segundos) y realizó el mismo número de comparaciones que la búsqueda secuencial (hasta 5000), lo cual indica que, en este caso, su naturaleza probabilística y su capacidad de inserción no ofrecieron ventajas competitivas frente a los algoritmos clásicos. Esto es consistente con el comportamiento teórico de esta estructura, que tiende a estabilizarse en consultas múltiples pero no necesariamente destaca en listas estáticas y ordenadas (Pugh, 1990)."
  },
  {
    "objectID": "SegundoDavid_U4_T1.html#análisis-sobre-perturbaciones.",
    "href": "SegundoDavid_U4_T1.html#análisis-sobre-perturbaciones.",
    "title": "\nReporte escrito. Experimentos y análisis de algoritmos de búsqueda por comparación.\n",
    "section": "Análisis sobre perturbaciones.",
    "text": "Análisis sobre perturbaciones.\n\nBúsqueda binaria\nMantuvo un número de comparaciones constante (~5.8) en todos los niveles de perturbación. Esta resistencia al desorden es una propiedad bien documentada (Cook & Kim, 1980), quienes demostraron que la binaria sigue siendo efectiva incluso en listas “casi ordenadas”.\nBúsqueda secuencial (B₀)\nContinuó mostrando su debilidad con 50.5 comparaciones promedio, incluso en listas levemente perturbadas. Esta falta de adaptabilidad confirma que su complejidad O(n) la hace poco recomendable fuera de conjuntos pequeños.\nBúsqueda no acotada B₁\nPromedió 10.66 comparaciones, lo que representa una mejora considerable sobre B₀. Sin embargo, sigue siendo menos eficiente que la búsqueda binaria. Esta estrategia se beneficia de su diseño recursivo para determinar un límite superior de búsqueda, aunque es más sensible al patrón de distribución de los datos.\nBúsqueda no acotada B₂\nFue ligeramente más eficiente que B₁ con 9.2 comparaciones, validando los hallazgos de Estivill-Castro & Wood (1992), quienes proponen que algoritmos adaptativos son preferibles cuando el orden o tamaño de los datos es incierto.\nSkipList\nAunque su diseño sugiere buena adaptabilidad, el rendimiento fue equivalente a B₀ (50.5 comparaciones) con tiempos mayores (1.4e-5 a 1.6e-5 segundos). En este experimento, su acceso probabilístico no logró mitigar el impacto del desorden, probablemente porque los datos no favorecían su reorganización progresiva (Pugh, 1990)."
  }
]